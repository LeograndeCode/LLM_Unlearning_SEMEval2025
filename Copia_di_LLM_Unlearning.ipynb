{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f21eba0a1a240fd8093b9ef87a98615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5114c69b14b4427d949cb14c841e693a",
              "IPY_MODEL_9d634c751bfb47fe9b554d013bfb32aa",
              "IPY_MODEL_90b67f779fc148faaac69f1d02b11566"
            ],
            "layout": "IPY_MODEL_9cc2a3f70e0343478c8cadf1923639ca"
          }
        },
        "5114c69b14b4427d949cb14c841e693a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f5b40e2b6ca434599313d890d677975",
            "placeholder": "​",
            "style": "IPY_MODEL_23caae5cb4464fcfbe37bbd7715f0223",
            "value": "Fetching 7 files: 100%"
          }
        },
        "9d634c751bfb47fe9b554d013bfb32aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3504289749b4b6288ecbedcd04f1286",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5fd8a29ce3040b3b2ecd4df50d872d9",
            "value": 7
          }
        },
        "90b67f779fc148faaac69f1d02b11566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0478cddabb34885bc24e38465f8498e",
            "placeholder": "​",
            "style": "IPY_MODEL_1af7979b52124d7e9128f2dbc6397392",
            "value": " 7/7 [00:00&lt;00:00, 249.75it/s]"
          }
        },
        "9cc2a3f70e0343478c8cadf1923639ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f5b40e2b6ca434599313d890d677975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23caae5cb4464fcfbe37bbd7715f0223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3504289749b4b6288ecbedcd04f1286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5fd8a29ce3040b3b2ecd4df50d872d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0478cddabb34885bc24e38465f8498e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af7979b52124d7e9128f2dbc6397392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8995f5e440894d748a433cd2fcb95250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_272e9542ef184f849993a15d2e04b41b",
              "IPY_MODEL_c474fc34741248bea27c843c04e21710",
              "IPY_MODEL_46786502fc594a5a9131b6fe01f9494c"
            ],
            "layout": "IPY_MODEL_0c8893764260409fb49bc25437ce30b5"
          }
        },
        "272e9542ef184f849993a15d2e04b41b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08109c1d98354de6a93fda1f1e04ae0e",
            "placeholder": "​",
            "style": "IPY_MODEL_e8aa2cdf0bff4c948cb5e31db2fa07c2",
            "value": "Fetching 10 files: 100%"
          }
        },
        "c474fc34741248bea27c843c04e21710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b92bbddae1c3417c8bb3002263db94e6",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e215add279f64d7cabc4b08976f3498e",
            "value": 10
          }
        },
        "46786502fc594a5a9131b6fe01f9494c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8b737906c754ba3a534bc5e395c0944",
            "placeholder": "​",
            "style": "IPY_MODEL_0c678bdd102947b9a54ae60e9a657b00",
            "value": " 10/10 [00:00&lt;00:00, 179.54it/s]"
          }
        },
        "0c8893764260409fb49bc25437ce30b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08109c1d98354de6a93fda1f1e04ae0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8aa2cdf0bff4c948cb5e31db2fa07c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b92bbddae1c3417c8bb3002263db94e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e215add279f64d7cabc4b08976f3498e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8b737906c754ba3a534bc5e395c0944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c678bdd102947b9a54ae60e9a657b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fd0d75bd88f4c099b6107555e08fc56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7ba1e54d81c4039882f6f4249243bdd",
              "IPY_MODEL_d0abb205172f44d4af931e648b91a994",
              "IPY_MODEL_9f56d6ec7bdf46b89e2e755479c4ae39"
            ],
            "layout": "IPY_MODEL_2cbe927c198e4e63a10c851993f7c626"
          }
        },
        "b7ba1e54d81c4039882f6f4249243bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ecf997287ec47828574ece65fc9116b",
            "placeholder": "​",
            "style": "IPY_MODEL_77542b7f6d48414bb2c51afa6320720a",
            "value": "Map: 100%"
          }
        },
        "d0abb205172f44d4af931e648b91a994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10d181983ed24b84af85a544791f76b1",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d50e2987c6745c5a76c1b3fe9aef5e0",
            "value": 612
          }
        },
        "9f56d6ec7bdf46b89e2e755479c4ae39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ee47f37c6fe4d94a8443b1715c2a41e",
            "placeholder": "​",
            "style": "IPY_MODEL_95603da170fc48d5ae9cf9bf86ae7e36",
            "value": " 612/612 [00:00&lt;00:00, 1271.36 examples/s]"
          }
        },
        "2cbe927c198e4e63a10c851993f7c626": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ecf997287ec47828574ece65fc9116b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77542b7f6d48414bb2c51afa6320720a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10d181983ed24b84af85a544791f76b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d50e2987c6745c5a76c1b3fe9aef5e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ee47f37c6fe4d94a8443b1715c2a41e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95603da170fc48d5ae9cf9bf86ae7e36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62931d4fbb0c45e98f4d36fde53f2377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5d0356a0f194f91adb95d3dc2aafe98",
              "IPY_MODEL_815288c7dde648a78f16712075c06160",
              "IPY_MODEL_47fd6082410343dca638b287ceb87eac"
            ],
            "layout": "IPY_MODEL_2ecb7bd33fe24d20a5439b31194b4ec2"
          }
        },
        "c5d0356a0f194f91adb95d3dc2aafe98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_748f4e318be04f7e8e7ee3f9a0d2719a",
            "placeholder": "​",
            "style": "IPY_MODEL_2184c8b4eb3e4a57a1d301211e40f408",
            "value": "Map: 100%"
          }
        },
        "815288c7dde648a78f16712075c06160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c3692299ec5436689f54aacee0fcdda",
            "max": 642,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47f3c7e77c8b4687a9c629fd0eb46a84",
            "value": 642
          }
        },
        "47fd6082410343dca638b287ceb87eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_905408eaac0445cb97a36048b9a44cb0",
            "placeholder": "​",
            "style": "IPY_MODEL_09166e4987be43f19e57c772ea29cf22",
            "value": " 642/642 [00:00&lt;00:00, 1108.43 examples/s]"
          }
        },
        "2ecb7bd33fe24d20a5439b31194b4ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "748f4e318be04f7e8e7ee3f9a0d2719a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2184c8b4eb3e4a57a1d301211e40f408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c3692299ec5436689f54aacee0fcdda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47f3c7e77c8b4687a9c629fd0eb46a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "905408eaac0445cb97a36048b9a44cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09166e4987be43f19e57c772ea29cf22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e28dd28e2d794ccbbe5cd0410db0a904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8e9d2e91d5f43ada9aa8c8843e047a3",
              "IPY_MODEL_ef936e73eb564784ae98c8ae2761ae37",
              "IPY_MODEL_7d7e4a9abb3040bf8a7ea5d44cf0c12b"
            ],
            "layout": "IPY_MODEL_7c0ab34c7c1d466fa4b6b028ed34bb04"
          }
        },
        "a8e9d2e91d5f43ada9aa8c8843e047a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e6ca05f475c494084490e8033125f22",
            "placeholder": "​",
            "style": "IPY_MODEL_3543c5e94a3846258300dcaab9613b1f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ef936e73eb564784ae98c8ae2761ae37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4a05c6e6cbb494ebeab326525983aa9",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_228a7fbb12f348e1a11989a0fc025b67",
            "value": 2
          }
        },
        "7d7e4a9abb3040bf8a7ea5d44cf0c12b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23053daebf1046c88416a8c24b3328a9",
            "placeholder": "​",
            "style": "IPY_MODEL_4b120b577efc4a9dbc6f1f8709f092f2",
            "value": " 2/2 [00:04&lt;00:00,  1.76s/it]"
          }
        },
        "7c0ab34c7c1d466fa4b6b028ed34bb04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e6ca05f475c494084490e8033125f22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3543c5e94a3846258300dcaab9613b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4a05c6e6cbb494ebeab326525983aa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "228a7fbb12f348e1a11989a0fc025b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23053daebf1046c88416a8c24b3328a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b120b577efc4a9dbc6f1f8709f092f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bc2f6b6229b4b6cb5d974aabe22b709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_228aaab376334353ac72c739438cf6ea",
              "IPY_MODEL_0f855c92352f429b8c20fa204eb4fb30",
              "IPY_MODEL_4c5cd494ed8f4cba9f77f13e39f921e2"
            ],
            "layout": "IPY_MODEL_9a3ecf9e308f48ab939d670e813bbcca"
          }
        },
        "228aaab376334353ac72c739438cf6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60ff554f7fdb43cc901316fe1b397b05",
            "placeholder": "​",
            "style": "IPY_MODEL_bf406c0f7c7d4e1b9e1d97b9db42d69b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0f855c92352f429b8c20fa204eb4fb30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46b7f782249e40169c27713f0b33e9f3",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87d25c3ca6784add947416cbfb088294",
            "value": 2
          }
        },
        "4c5cd494ed8f4cba9f77f13e39f921e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4a3f1c497a84718acf1b1d2aaf90e80",
            "placeholder": "​",
            "style": "IPY_MODEL_6423cc4c77864cac95c94d63b1af80fb",
            "value": " 2/2 [00:01&lt;00:00,  1.35it/s]"
          }
        },
        "9a3ecf9e308f48ab939d670e813bbcca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60ff554f7fdb43cc901316fe1b397b05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf406c0f7c7d4e1b9e1d97b9db42d69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46b7f782249e40169c27713f0b33e9f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87d25c3ca6784add947416cbfb088294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4a3f1c497a84718acf1b1d2aaf90e80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6423cc4c77864cac95c94d63b1af80fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeograndeCode/LLM_Unlearning_SEMEval2025/blob/silvia-branch/Copia_di_LLM_Unlearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initial Setup\n"
      ],
      "metadata": {
        "id": "2BevAv496zow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging, sys\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    stream=sys.stdout\n",
        ")\n",
        "logger = logging.getLogger()\n",
        "\n"
      ],
      "metadata": {
        "id": "DNnjDJhvr0HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading model and datasets\n"
      ],
      "metadata": {
        "id": "Vq-2vlQA7V9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains disjoint retain and forget splits in parquet files, and includes following fields: id, input, output, task.\n",
        "* Subtask 1: Long form synthetic creative documents spanning different\n",
        "genres.\n",
        "* Subtask 2: Short form synthetic biographies containing personally identifiable information (PII), including fake names, phone number, SSN, email and home addresses.\n",
        "* Subtask 3: Real documents sampled from the target model’s training dataset."
      ],
      "metadata": {
        "id": "EK35cs_ZWA88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "2f21eba0a1a240fd8093b9ef87a98615",
            "5114c69b14b4427d949cb14c841e693a",
            "9d634c751bfb47fe9b554d013bfb32aa",
            "90b67f779fc148faaac69f1d02b11566",
            "9cc2a3f70e0343478c8cadf1923639ca",
            "3f5b40e2b6ca434599313d890d677975",
            "23caae5cb4464fcfbe37bbd7715f0223",
            "f3504289749b4b6288ecbedcd04f1286",
            "f5fd8a29ce3040b3b2ecd4df50d872d9",
            "b0478cddabb34885bc24e38465f8498e",
            "1af7979b52124d7e9128f2dbc6397392",
            "8995f5e440894d748a433cd2fcb95250",
            "272e9542ef184f849993a15d2e04b41b",
            "c474fc34741248bea27c843c04e21710",
            "46786502fc594a5a9131b6fe01f9494c",
            "0c8893764260409fb49bc25437ce30b5",
            "08109c1d98354de6a93fda1f1e04ae0e",
            "e8aa2cdf0bff4c948cb5e31db2fa07c2",
            "b92bbddae1c3417c8bb3002263db94e6",
            "e215add279f64d7cabc4b08976f3498e",
            "e8b737906c754ba3a534bc5e395c0944",
            "0c678bdd102947b9a54ae60e9a657b00"
          ]
        },
        "id": "PCDXt1Ab6U-S",
        "outputId": "eef0b1a7-01f3-4e6d-c9a5-3902b23e764a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f21eba0a1a240fd8093b9ef87a98615"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8995f5e440894d748a433cd2fcb95250"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘train’: File exists\n",
            "mkdir: cannot create directory ‘validation’: File exists\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from huggingface_hub import snapshot_download\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from google.colab import userdata\n",
        "#hf_token = userdata.get('HF_TOKEN')\n",
        "hf_token = \"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\"\n",
        "## Fetch and load model:\n",
        "snapshot_download(repo_id='llmunlearningsemeval2025organization/olmo-1B-model-semeval25-unlearning', token=hf_token, local_dir='semeval25-unlearning-1B-model')\n",
        "# model = AutoModelForCausalLM.from_pretrained('semeval25-unlearning-1B-model').to('cuda')\n",
        "\n",
        "## Fetch and load dataset:\n",
        "snapshot_download(repo_id='llmunlearningsemeval2025organization/semeval25-unlearning-dataset-public', token=hf_token, local_dir='semeval25-unlearning-data', repo_type=\"dataset\")\n",
        "retain_train_df = pd.read_parquet('semeval25-unlearning-data/data/retain_train-00000-of-00001.parquet', engine='pyarrow') # Retain split: train set\n",
        "retain_validation_df = pd.read_parquet('semeval25-unlearning-data/data/retain_validation-00000-of-00001.parquet', engine='pyarrow') # Retain split: validation set\n",
        "forget_train_df = pd.read_parquet('semeval25-unlearning-data/data/forget_train-00000-of-00001.parquet', engine='pyarrow') # Forget split: train set\n",
        "forget_validation_df = pd.read_parquet('semeval25-unlearning-data/data/forget_validation-00000-of-00001.parquet', engine='pyarrow') # Forget split: validation set\n",
        "!mkdir train validation\n",
        "retain_train_df.to_json('train/retain.jsonl', orient='records', lines=True); forget_train_df.to_json('train/forget.jsonl', orient='records', lines=True)\n",
        "retain_validation_df.to_json('validation/retain.jsonl', orient='records', lines=True); forget_validation_df.to_json('validation/forget.jsonl', orient='records', lines=True)\n",
        "\n",
        "\n",
        "# ==== DEBUG: usa solo una porzione del dataset ====\n",
        "# sample_size = 100  # numero di esempi per split\n",
        "# retain_train_df     = retain_train_df.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
        "# forget_train_df     = forget_train_df.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
        "# retain_validation_df = retain_validation_df.sample(n=sample_size//10, random_state=42).reset_index(drop=True)\n",
        "# forget_validation_df = forget_validation_df.sample(n=sample_size//10, random_state=42).reset_index(drop=True)\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "\n",
        "# filter the data to include only one task (e.g., Task2)\n",
        "forget_train_df = forget_train_df[forget_train_df[\"task\"] == \"Task2\"]\n",
        "retain_train_df = retain_train_df[retain_train_df[\"task\"] == \"Task2\"]\n",
        "forget_val_df = forget_validation_df[forget_validation_df[\"task\"] == \"Task2\"]\n",
        "retain_val_df = retain_validation_df[retain_validation_df[\"task\"] == \"Task2\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Dataloaders for Retain and Forget Set\n"
      ],
      "metadata": {
        "id": "jfiqI4VgWRQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/OLMo-1B-0724-hf\")\n",
        "\n",
        "def tokenize_with_start(example):\n",
        "    q, a = example[\"input\"], example[\"output\"]\n",
        "    prefix = q\n",
        "    full   = q + a\n",
        "\n",
        "    # 1) tokenizza solo per contare i token reali (no pad)\n",
        "    t_pref = tokenizer(prefix, truncation=True, padding=False)\n",
        "    start_locs = len(t_pref[\"input_ids\"])\n",
        "\n",
        "    # 2) tokenizza la coppia vera e propria con pad/trunc\n",
        "    t_full = tokenizer(full, truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "    return {\n",
        "      \"input_ids\":      t_full[\"input_ids\"],\n",
        "      \"attention_mask\": t_full[\"attention_mask\"],\n",
        "      \"labels\":         t_full[\"input_ids\"],\n",
        "      \"start_locs\":     start_locs,\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18S3qB2Iyepm",
        "outputId": "41d1fe31-8ee3-4c48-f9b5-1eb30ff47881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install datasets\n",
        "from datasets import Dataset\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "# 1. Crea HF Dataset\n",
        "ds_retain = Dataset.from_pandas(retain_train_df)\n",
        "ds_forget = Dataset.from_pandas(forget_train_df)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/OLMo-1B-0724-hf\")\n",
        "\n",
        "# 2. Tokenizer function\n",
        "# def tokenize_fn(example):\n",
        "#     tokens = tokenizer(\n",
        "#         example[\"input\"],\n",
        "#         text_target=example[\"output\"],\n",
        "#         padding=\"max_length\",\n",
        "#         truncation=True,\n",
        "#         max_length=128,\n",
        "#     )\n",
        "#     return tokens\n",
        "\n",
        "# 3. Applica\n",
        "\n",
        "ds_retain = Dataset.from_pandas(retain_train_df).map(\n",
        "    tokenize_with_start, batched=False, load_from_cache_file=False\n",
        ")\n",
        "\n",
        "ds_forget = Dataset.from_pandas(forget_train_df).map(\n",
        "    tokenize_with_start, batched=False, load_from_cache_file=False\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 4. Crea DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return {\n",
        "        \"input_ids\": torch.tensor([x[\"input_ids\"] for x in batch]),\n",
        "        \"attention_mask\": torch.tensor([x[\"attention_mask\"] for x in batch]),\n",
        "        \"labels\": torch.tensor([x[\"labels\"] for x in batch]),\n",
        "        \"start_locs\": torch.tensor([x[\"start_locs\"] for x in batch]),  # <- questa riga è fondamentale\n",
        "    }\n",
        "\n",
        "\n",
        "train_normal_loader = DataLoader(ds_retain, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "train_bad_loader    = DataLoader(ds_forget, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119,
          "referenced_widgets": [
            "0fd0d75bd88f4c099b6107555e08fc56",
            "b7ba1e54d81c4039882f6f4249243bdd",
            "d0abb205172f44d4af931e648b91a994",
            "9f56d6ec7bdf46b89e2e755479c4ae39",
            "2cbe927c198e4e63a10c851993f7c626",
            "2ecf997287ec47828574ece65fc9116b",
            "77542b7f6d48414bb2c51afa6320720a",
            "10d181983ed24b84af85a544791f76b1",
            "8d50e2987c6745c5a76c1b3fe9aef5e0",
            "1ee47f37c6fe4d94a8443b1715c2a41e",
            "95603da170fc48d5ae9cf9bf86ae7e36",
            "62931d4fbb0c45e98f4d36fde53f2377",
            "c5d0356a0f194f91adb95d3dc2aafe98",
            "815288c7dde648a78f16712075c06160",
            "47fd6082410343dca638b287ceb87eac",
            "2ecb7bd33fe24d20a5439b31194b4ec2",
            "748f4e318be04f7e8e7ee3f9a0d2719a",
            "2184c8b4eb3e4a57a1d301211e40f408",
            "6c3692299ec5436689f54aacee0fcdda",
            "47f3c7e77c8b4687a9c629fd0eb46a84",
            "905408eaac0445cb97a36048b9a44cb0",
            "09166e4987be43f19e57c772ea29cf22"
          ]
        },
        "id": "zE9nf-SCpo-e",
        "outputId": "d31835fb-e66a-42ba-9edd-ec617f05edec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/612 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0fd0d75bd88f4c099b6107555e08fc56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/642 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62931d4fbb0c45e98f4d36fde53f2377"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install -U bitsandbytes"
      ],
      "metadata": {
        "id": "NcwubcF50ArO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import prepare_model_for_kbit_training, get_peft_model, LoraConfig\n",
        "\n",
        "# 1) Configurazione 8-bit\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,               # carica in 8-bit\n",
        "    llm_int8_threshold=6.0           # soglia consigliata\n",
        ")\n",
        "\n",
        "# 2) Carica tokenizer (non cambia)\n",
        "\n",
        "# 3) Carica model e pretrained_model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"semeval25-unlearning-1B-model\",\n",
        "    quantization_config=bnb_config,   # <-- 8-bit qui\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "model.config.clip_qkv = None\n",
        "\n",
        "pretrained_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"semeval25-unlearning-1B-model\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "\n",
        "# 4) Gradient checkpointing\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "# 5) Prepara per LoRA\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "lora_cfg = LoraConfig(\n",
        "    r=16,                             # rango LoRA\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\",\"v_proj\"],\n",
        "    inference_mode=False,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_cfg)\n",
        "model.print_trainable_parameters()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "e28dd28e2d794ccbbe5cd0410db0a904",
            "a8e9d2e91d5f43ada9aa8c8843e047a3",
            "ef936e73eb564784ae98c8ae2761ae37",
            "7d7e4a9abb3040bf8a7ea5d44cf0c12b",
            "7c0ab34c7c1d466fa4b6b028ed34bb04",
            "0e6ca05f475c494084490e8033125f22",
            "3543c5e94a3846258300dcaab9613b1f",
            "d4a05c6e6cbb494ebeab326525983aa9",
            "228a7fbb12f348e1a11989a0fc025b67",
            "23053daebf1046c88416a8c24b3328a9",
            "4b120b577efc4a9dbc6f1f8709f092f2",
            "4bc2f6b6229b4b6cb5d974aabe22b709",
            "228aaab376334353ac72c739438cf6ea",
            "0f855c92352f429b8c20fa204eb4fb30",
            "4c5cd494ed8f4cba9f77f13e39f921e2",
            "9a3ecf9e308f48ab939d670e813bbcca",
            "60ff554f7fdb43cc901316fe1b397b05",
            "bf406c0f7c7d4e1b9e1d97b9db42d69b",
            "46b7f782249e40169c27713f0b33e9f3",
            "87d25c3ca6784add947416cbfb088294",
            "f4a3f1c497a84718acf1b1d2aaf90e80",
            "6423cc4c77864cac95c94d63b1af80fb"
          ]
        },
        "id": "nHeRuz3bpr3k",
        "outputId": "3ae2897e-3b41-415d-ab98-37a6e2408db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e28dd28e2d794ccbbe5cd0410db0a904"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bc2f6b6229b4b6cb5d974aabe22b709"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 2,097,152 || all params: 1,281,884,160 || trainable%: 0.1636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8IGoNL-p1FNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.quantization as quant\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#     \"semeval25-unlearning-1B-model\",\n",
        "#     torch_dtype=torch.float16  # Use half precision\n",
        "# ).to(device)\n",
        "# pretrained_model = AutoModelForCausalLM.from_pretrained(\n",
        "#     \"semeval25-unlearning-1B-model\",\n",
        "#     torch_dtype=torch.float16  # Use half precision\n",
        "# ).to(device)\n",
        "\n",
        "# model.gradient_checkpointing_enable()"
      ],
      "metadata": {
        "id": "_NupWI4SyW8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Loss functions\n"
      ],
      "metadata": {
        "id": "1aEjqbjRZSQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#rimaste uguali\n",
        "\n",
        "# def compute_reverse_kl(pretrained_model, current_model, batch, device):\n",
        "#     \"\"\"\n",
        "#     Compute *backward* KL as the normal utility loss.\n",
        "\n",
        "#     Args:\n",
        "#         pretrained_model: reference model which is the pretrained (original) model.\n",
        "#         current_model: The current unlearning model.\n",
        "#         batch: A batch of normal data.\n",
        "#         device: GPU device.\n",
        "\n",
        "#     Returns:\n",
        "#        The KL loss.\n",
        "#     \"\"\"\n",
        "\n",
        "#     normal_outputs = current_model(\n",
        "#         batch[\"input_ids\"].to(device),\n",
        "#         attention_mask=batch[\"attention_mask\"].to(device)\n",
        "#     )\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         pretrained_outputs = pretrained_model(\n",
        "#             batch[\"input_ids\"].to(device),\n",
        "#             attention_mask=batch[\"attention_mask\"].to(device)\n",
        "#         )\n",
        "\n",
        "#     # Q: current model; P: pretrained model.\n",
        "#     prob_q = torch.nn.functional.softmax(normal_outputs.logits, dim=-1)\n",
        "#     prob_p = torch.nn.functional.softmax(pretrained_outputs.logits, dim=-1)\n",
        "\n",
        "#     # Negative KL divergence: sum(Q * log(Q/P))\n",
        "#     # loss = (prob_q * torch.log(prob_q / (prob_p + 1e-12))).sum(-1).mean()\n",
        "#     loss = - (prob_p * torch.log((prob_p + 1e-12) / prob_q)).sum(-1).mean()\n",
        "\n",
        "#     return loss\n",
        "\n",
        "def get_answer_loss(operation, batch, model, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    Compute the loss on the answer (i.e. y) part.\n",
        "\n",
        "    Args:\n",
        "        operation: either \"ga\" (gradient ascent) or \"gd\" (gradient descent).\n",
        "        batch: A batch of data.\n",
        "        model: The unlearned model.\n",
        "        device: GPU device.\n",
        "\n",
        "    Returns:\n",
        "       The loss.\n",
        "    \"\"\"\n",
        "    assert operation in [\"ga\", \"gd\"], \"Operation must be either GA or GD.\"\n",
        "    input_ids, attention_mask, start_locs, labels = (\n",
        "        batch[\"input_ids\"].to(device),\n",
        "        batch[\"attention_mask\"].to(device),\n",
        "        batch[\"start_locs\"],\n",
        "        batch[\"labels\"].to(device),\n",
        "    )\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    loss_fct = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    # Shift one to predict next token.\n",
        "    shift_logits = outputs.logits[:, :-1, :]\n",
        "    shift_labels = labels[:, 1:]\n",
        "    losses = []\n",
        "    for bid in range(input_ids.shape[0]):\n",
        "        one_inp, one_st = input_ids[bid], start_locs[bid]\n",
        "\n",
        "        # GA or GD.\n",
        "        position_loss = loss_fct(shift_logits[bid], shift_labels[bid])\n",
        "\n",
        "        if operation == \"ga\":  # Negative the direction for GA.\n",
        "            position_loss = -position_loss\n",
        "\n",
        "        # Simply put equal weights on all answers.\n",
        "        position_weight = torch.zeros_like(one_inp)\n",
        "        assert len(position_weight) == len(position_loss) + 1\n",
        "        position_weight[one_st:] = 1  # only focus on answer part\n",
        "\n",
        "        # Ignore the padding part.\n",
        "        position_weight[one_inp == 1] = 0\n",
        "        if position_weight.sum() > 0:\n",
        "            position_weight = position_weight / position_weight.sum()\n",
        "\n",
        "        one_loss = (position_weight[:-1] * position_loss).sum()\n",
        "        losses.append(one_loss)\n",
        "\n",
        "    final_loss = torch.stack(losses).mean()\n",
        "\n",
        "    return final_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "VkADKV-b18M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "import random\n",
        "import torch\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_reverse_kl(pretrained_model, current_model, batch, device):\n",
        "    \"\"\"\n",
        "    Compute reverse KL divergence D_KL(P || Q) = sum_x P(x) * log(P(x)/Q(x))\n",
        "    in modo numericamente stabile usando log-softmax.\n",
        "\n",
        "    Args:\n",
        "        pretrained_model: modello di riferimento (P; fp32)\n",
        "        current_model:    modello in training    (Q; quantizzato+LoRA)\n",
        "        batch:            dict con input_ids, attention_mask\n",
        "        device:           'cuda' o simili\n",
        "    Returns:\n",
        "        loss scalare (mean over batch and seq)\n",
        "    \"\"\"\n",
        "    # 1) Forward pass di current model (Q)\n",
        "    out_q = current_model(\n",
        "        batch[\"input_ids\"].to(device),\n",
        "        attention_mask=batch[\"attention_mask\"].to(device)\n",
        "    )\n",
        "    logits_q = out_q.logits  # [B, T, V]\n",
        "\n",
        "    # 2) Forward pass di pretrained model (P), senza grad\n",
        "    with torch.no_grad():\n",
        "        out_p = pretrained_model(\n",
        "            batch[\"input_ids\"].to(device),\n",
        "            attention_mask=batch[\"attention_mask\"].to(device)\n",
        "        )\n",
        "        logits_p = out_p.logits  # [B, T, V]\n",
        "\n",
        "    # 3) log-softmax (numerically stable)\n",
        "    logp = F.log_softmax(logits_p, dim=-1)  # log P(x)\n",
        "    logq = F.log_softmax(logits_q, dim=-1)  # log Q(x)\n",
        "\n",
        "    # 4) P(x) = exp(logp)\n",
        "    p_prob = torch.exp(logp)\n",
        "\n",
        "    # 5) compute reverse KL = - sum_x P * (logp - logq)\n",
        "    #    (negative because we minimize)\n",
        "    kl_per_token = -(p_prob * (logp - logq)).sum(dim=-1)  # [B, T]\n",
        "    loss = kl_per_token.mean()  # scalar\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def get_rand_ans_loss(bad_batch, tokenizer, normal_ans, model, K=5, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    Random Disassociation: per ogni domanda nel batch, campiona K answers dal retain set,\n",
        "    crea batch di testi `Question + Answer`, e chiama get_answer_loss(\"gd\", ...).\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Decodifica le domande dal batch di input_ids\n",
        "    #    skip_special_tokens=True per togliere pad/eos\n",
        "    questions = tokenizer.batch_decode(\n",
        "        bad_batch[\"input_ids\"], skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    features = []\n",
        "    for question in questions:\n",
        "        prefix = question.strip()\n",
        "        # 2) Conta i token reali del prefix (no pad)\n",
        "        t_pref = tokenizer(prefix, truncation=True, padding=False)\n",
        "        start_loc = len(t_pref[\"input_ids\"])\n",
        "\n",
        "        # 3) Per ogni question campiona K risposte casuali dal tuo retain set\n",
        "        rand_samples = random.sample(normal_ans, K)\n",
        "        for ans in rand_samples:\n",
        "            text = prefix + ans\n",
        "            tok  = tokenizer(\n",
        "                text,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "                max_length=128\n",
        "            )\n",
        "            features.append({\n",
        "                \"input_ids\":      tok[\"input_ids\"],\n",
        "                \"attention_mask\": tok[\"attention_mask\"],\n",
        "                \"start_locs\":     start_loc,\n",
        "                \"labels\":         tok[\"input_ids\"],\n",
        "            })\n",
        "\n",
        "    # 4) Usa lo stesso DataCollator del training\n",
        "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "    batch_random = data_collator(features)\n",
        "\n",
        "    # 5) Loss di gradient *descent* sul segmento “answer”\n",
        "    return get_answer_loss(\"gd\", batch_random, model, device=device)\n"
      ],
      "metadata": {
        "id": "3L6wufmv1WES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "-NVNEi1uZmw1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "riproviamo qui:"
      ],
      "metadata": {
        "id": "TXcqWnGDx3S8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from transformers import get_scheduler\n",
        "from torch.optim import AdamW\n",
        "import random\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bad_weight = 1\n",
        "random_weight = 1\n",
        "normal_weight = 0.5\n",
        "batch_size = 1\n",
        "lr = 1e-4\n",
        "max_unlearn_steps = 2000\n",
        "# model_save_dir = \"semeval25-unlearning-model\"\n",
        "# task_vector_saving_path = \"semeval25-unlearning-model/task_vector\"\n",
        "accelerator = Accelerator()\n",
        "optimizer = AdamW(model.parameters(), lr=lr)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=max_unlearn_steps\n",
        ")\n",
        "\n",
        "retain_loader = DataLoader(ds_retain, batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "forget_loader = DataLoader(ds_forget, batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "bad_ans = retain_train_df[\"output\"].tolist()\n",
        "# Imposti quante iterazioni accumulare\n",
        "accumulation_steps = 4\n",
        "\n",
        "optimizer.zero_grad()\n",
        "idx = 0\n",
        "step = 0\n",
        "while idx < max_unlearn_steps:\n",
        "    for bad_batch, normal_batch in zip(forget_loader, retain_loader):\n",
        "        # 1) Computa tutte le loss\n",
        "        bad_loss    = get_answer_loss(\"gd\", bad_batch,    model, device)\n",
        "        random_loss = get_rand_ans_loss(bad_batch, tokenizer, bad_ans, model, device=device)\n",
        "        normal_loss = compute_reverse_kl(pretrained_model, model, normal_batch, device)\n",
        "\n",
        "        loss = (\n",
        "            bad_weight    * bad_loss\n",
        "          + random_weight * random_loss\n",
        "          + normal_weight * normal_loss\n",
        "        ) / accumulation_steps   # **dividi** la loss per il numero di accumuli\n",
        "        print(f\"GD: {bad_loss.item()}, RD: {random_loss.item()}, revKL: {normal_loss.item()}\")\n",
        "\n",
        "        accelerator.backward(loss)\n",
        "        for n, p in model.named_parameters():\n",
        "          if \"lora\" in n and p.grad is not None:\n",
        "            print(f\"{n} grad mean {p.grad.abs().mean():.6f}\")\n",
        "\n",
        "\n",
        "        # 2) Ogni accumulation_steps passi fai optimizer.step()\n",
        "        if (step + 1) % accumulation_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        idx += 1\n",
        "        step += 1\n",
        "\n",
        "        if idx % 100 == 0:\n",
        "          print(f\"GD_loss: {bad_loss}\")\n",
        "          print(f\"RD_loss: {random_loss}\")\n",
        "          print(f\"revKL_loss: {normal_loss}\")\n",
        "\n",
        "          print(f\"[{idx}] loss_combined={(loss*accumulation_steps):.2f}\")\n",
        "\n",
        "        if idx >= max_unlearn_steps:\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "# alla fine del loop di unlearning, se usi LoRA\n",
        "model = model.merge_and_unload()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bnc5i23ymwK",
        "outputId": "56d18645-cef9-46b1-e47a-0ed937f76936",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000673\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000703\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000463\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.021639\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000814\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000826\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000873\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.019123\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000785\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000991\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000749\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.014306\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000604\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000790\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000701\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.013467\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001619\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.002180\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000914\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.013023\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000969\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000817\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000673\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.011249\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000941\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000792\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000512\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.011626\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001278\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001360\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000725\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.012927\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001556\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001708\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000997\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.013605\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001276\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001275\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000724\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.016446\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001064\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001356\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001312\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.017015\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000960\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000956\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000813\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.017354\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001028\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001056\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001171\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.025462\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001837\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001445\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001309\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.036139\n",
            "GD: 0.27857184410095215, RD: 0.8561235666275024, revKL: -53.762794494628906\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000291\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000664\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.004853\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.021408\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000257\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001163\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000509\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.017032\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000308\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000297\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000284\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.022220\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000315\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000367\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.001009\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.020993\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000313\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000517\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000401\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.013893\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000374\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000469\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000303\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.013637\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001171\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001588\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000362\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.011324\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000513\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000365\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000323\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.010543\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000396\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000368\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000264\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.010176\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000764\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000910\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000731\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.011729\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000360\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000674\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000816\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.013115\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000649\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000550\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000450\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.018236\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000851\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000876\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000787\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.019318\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000470\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000605\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001036\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.019427\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000870\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000453\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001779\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.030713\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001017\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000633\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001733\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.037921\n",
            "GD: 2.987905263900757, RD: 0.9732934236526489, revKL: -31.108339309692383\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000611\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001261\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.005080\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.022186\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000395\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001521\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001100\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.016993\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000673\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000588\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000339\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.020676\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000881\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000898\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.001136\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.020183\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000792\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000933\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000779\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.014992\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000698\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000996\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000747\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.015602\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000865\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001323\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000480\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.013689\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000852\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000737\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000294\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.012989\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001002\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000657\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000607\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.013292\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001383\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001164\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000671\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.016050\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000973\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001080\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000982\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.019442\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001923\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001391\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.001003\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.021094\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001557\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001993\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000758\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.022387\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.002493\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001744\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001081\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.026331\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001569\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001840\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.002162\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.030545\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001871\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001418\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001732\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.033809\n",
            "GD: 0.7563756704330444, RD: 1.4390324354171753, revKL: -39.63383483886719\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000664\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001381\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.004965\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.022631\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000522\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001791\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001126\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.016997\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000827\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000721\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000428\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.020134\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000919\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000956\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.001080\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.019442\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000898\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001035\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000749\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.014935\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000756\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000986\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000807\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.015479\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000696\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001169\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000501\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.013686\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001077\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000798\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000379\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.013160\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001094\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000746\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000593\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.013670\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001408\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001200\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000712\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.016000\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000991\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001076\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000949\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.019158\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001931\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001442\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000976\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.020818\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001753\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.002193\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000873\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.022211\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.002628\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001899\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001099\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.025889\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001618\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001907\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001891\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.030152\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001980\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001442\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001591\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.033919\n",
            "GD: 2.1984903812408447, RD: 1.053710699081421, revKL: -36.20463180541992\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000712\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001566\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.006259\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.026148\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000665\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.002230\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001385\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.019675\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000919\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000846\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000435\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.021088\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000911\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001011\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000751\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.020044\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001063\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001203\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000772\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.015968\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000778\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.001022\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.001055\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.016420\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001145\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001602\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000678\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.014370\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001055\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000842\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000432\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.013510\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001151\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000749\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000581\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.014312\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001604\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001403\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000687\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.016840\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001151\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001234\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001055\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.019632\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001954\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001464\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.001033\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.021108\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001903\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.002361\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001198\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.021950\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.002914\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.002176\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000984\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.025187\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001682\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001987\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001517\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.027508\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.002041\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001527\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001739\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.031665\n",
            "GD: 2.402601480484009, RD: 0.8307005167007446, revKL: -41.70702362060547\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000270\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000611\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.004208\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.019583\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000235\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001100\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000792\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.016062\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000659\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000415\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000378\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.016121\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000352\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000432\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000725\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.012912\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000529\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000611\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000309\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.009632\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000326\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000481\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000356\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.009619\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001171\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001539\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000473\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.008142\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000520\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000297\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000243\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.006857\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000409\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000272\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000184\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.006911\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000700\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000666\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000412\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.008395\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000335\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000559\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000373\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.009239\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000539\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000361\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000471\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.011380\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000620\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000520\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000676\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.012105\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001078\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000714\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000633\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.011804\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000513\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000478\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000946\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.017416\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000827\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000497\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001252\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.022031\n",
            "GD: 1.7667522430419922, RD: 1.2272987365722656, revKL: -43.71461486816406\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000373\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000863\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.005251\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.024283\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000317\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001446\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000938\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.019264\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000807\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000605\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000422\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.019594\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000451\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000541\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000811\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.016036\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000633\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000867\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000323\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.012159\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000438\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000611\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000421\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.011957\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001357\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001768\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000523\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.010050\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000530\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000378\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000283\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.008556\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000443\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000323\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000233\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.008571\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000829\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000810\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000446\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.010325\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000440\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000796\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000525\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.011319\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000623\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000461\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000501\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.014410\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000736\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000743\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000808\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.015231\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000984\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000730\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000749\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.014660\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000691\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000618\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001182\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.021351\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000889\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000634\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001453\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.025465\n",
            "GD: 1.7852526903152466, RD: 1.5692875385284424, revKL: -41.361534118652344\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000501\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001082\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.005805\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.027856\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000423\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001831\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001196\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.021516\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000854\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000718\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000604\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.021506\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000590\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000724\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000893\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.018187\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000902\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001165\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000378\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.014922\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000471\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000715\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000464\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.013986\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001274\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001856\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000558\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.012018\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000928\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000522\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000404\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.010405\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000727\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000500\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000310\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.010350\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000967\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001028\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000451\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.012197\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000655\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000929\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000565\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.013313\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001045\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000764\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000589\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.017639\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000852\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000851\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001206\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.018413\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001066\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000891\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000844\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.018056\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000902\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000780\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001169\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.027048\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001122\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000860\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001653\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.029866\n",
            "GD: 2.79416823387146, RD: 0.7159746289253235, revKL: -34.75101852416992\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000726\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001618\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.009421\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.047814\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000538\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.002585\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.002115\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.030801\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001635\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001267\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000824\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.032302\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000872\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001100\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.001489\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.025781\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001211\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001614\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000697\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.020159\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000827\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.001015\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000833\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.021069\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.002054\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.002851\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.001045\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.017849\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001275\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000854\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000683\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.015076\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001095\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000757\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000538\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.015187\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.002314\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001927\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000693\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.017760\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.002046\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001910\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000735\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.019027\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001371\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001099\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.001349\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.024050\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001294\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001423\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001760\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.025626\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001554\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001303\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001336\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.025675\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001375\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001370\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001761\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.038045\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.002050\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001663\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.002341\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.037295\n",
            "GD: 0.5602515935897827, RD: 1.0267740488052368, revKL: -52.38465881347656\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000621\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000769\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001112\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.008498\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000287\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000845\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000358\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.007936\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000534\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000388\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000127\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.009173\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000261\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000303\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000248\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.008484\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000303\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000399\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000214\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.006247\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000281\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000345\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000285\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.006091\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000562\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000856\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000332\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.005263\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000500\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000230\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000117\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.004968\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000415\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000250\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000224\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.004612\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000353\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000354\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000155\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.005443\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000690\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000771\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000295\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.005457\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000508\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000385\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000327\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.006961\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000643\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000425\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000425\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.007553\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000415\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000450\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000659\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.007446\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000344\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000255\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000625\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.011875\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000766\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000591\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000968\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.017462\n",
            "GD: 0.7086330652236938, RD: 0.5212773084640503, revKL: -19.49481201171875\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000656\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000873\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001221\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.010038\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000335\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001057\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000569\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.009074\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000709\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000539\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000174\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.010741\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000416\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000444\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000398\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.010060\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000509\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000476\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000388\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.007601\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000453\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000469\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000416\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.007573\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000908\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001251\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000391\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.007024\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001034\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000451\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000348\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.006759\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000556\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000429\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000375\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.006405\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000534\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000499\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000567\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.007263\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000802\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000958\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000636\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.007963\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000776\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000670\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000640\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.009678\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000963\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000952\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001094\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.010207\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000733\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000698\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000815\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.009747\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000742\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000500\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001100\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.014447\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001395\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001084\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001309\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.021155\n",
            "GD: 6.784226417541504, RD: 0.7005126476287842, revKL: -39.70777130126953\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000768\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001876\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002969\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.027756\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000722\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.002417\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001531\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.018544\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001309\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001366\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000741\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.019402\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.001175\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001260\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.001009\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.017938\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001491\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001322\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000940\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.016461\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.001070\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.001277\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.001408\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.017669\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001872\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.002208\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000814\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.016480\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.002029\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.001062\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000877\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.014939\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001411\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.001058\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000743\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.013929\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001918\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001605\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.001334\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.016373\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.002389\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.002701\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001263\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.018599\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001280\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001421\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.001097\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.018951\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.002230\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.002555\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.002485\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.020684\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001752\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001706\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001562\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.019872\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001842\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001367\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001574\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.026122\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.002788\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.002259\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.002711\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.030557\n",
            "GD: 0.2878752648830414, RD: 0.7907031774520874, revKL: -44.48084259033203\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000788\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001880\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.003226\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.028296\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000739\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.002455\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001522\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.019644\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001353\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001430\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000762\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.020882\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.001208\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001299\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.001021\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.019767\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001493\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001362\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.001030\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.017600\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.001073\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.001273\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.001511\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.018715\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001922\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.002320\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000884\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.017556\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.002191\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.001102\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000917\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.015985\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001496\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.001134\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000830\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.014937\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001905\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001564\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.001278\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.017396\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.002531\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.002971\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001312\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.019726\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001341\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001534\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.001182\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.020340\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.002383\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.002684\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.002455\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.021939\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001816\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001823\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001722\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.021312\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001882\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001431\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001757\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.028533\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.003296\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.002562\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.003064\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.036006\n",
            "GD: 0.5062966346740723, RD: 1.53484046459198, revKL: -42.72883605957031\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000649\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001093\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001625\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.013599\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000605\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001438\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001097\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.009190\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000877\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001057\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000606\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.009535\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000829\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000764\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000332\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.008104\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001184\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001100\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000539\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.009323\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000596\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000720\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000628\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.008154\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000759\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000864\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000455\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.008750\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001033\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000765\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000486\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.008130\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001090\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000727\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000816\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.007934\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001023\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000969\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000465\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.007326\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000716\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000810\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000564\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.007182\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000832\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000788\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000668\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.008431\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000954\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001105\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000522\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.007333\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001036\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000890\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000317\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.006755\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000653\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000584\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000319\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.009115\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000948\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000731\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000594\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.011207\n",
            "GD: 0.4411381781101227, RD: 0.9528754353523254, revKL: -41.486385345458984\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000770\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001301\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001729\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.015163\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000651\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001642\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001167\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.010744\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001042\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001252\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000748\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.011546\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000897\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000879\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000397\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.010372\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001434\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001354\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000799\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.011372\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000794\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000950\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000995\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.010480\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001051\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001249\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000727\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.011177\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001456\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.001094\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000676\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.010305\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001238\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000926\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.001053\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.010143\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001286\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001213\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000603\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.009334\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000860\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000990\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000819\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.009035\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001068\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000948\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000796\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.010898\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001434\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001703\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000663\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.009800\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001360\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001121\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000442\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.009022\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000785\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000707\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000491\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.012318\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001391\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001080\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000679\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.016854\n",
            "GD: 0.9118984937667847, RD: 0.9272297024726868, revKL: -39.8091926574707\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000792\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001373\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.003097\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.020118\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000696\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001826\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001297\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.012901\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001068\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001257\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000726\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.014617\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000939\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000890\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000509\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.013278\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001423\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001359\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000856\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.013287\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000836\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.001089\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.001091\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.012529\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001398\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001804\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000827\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.012751\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001712\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.001341\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000762\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.011557\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001350\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.001017\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.001118\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.011504\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001637\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001449\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000704\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.010818\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000895\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001119\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000981\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.010900\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001209\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001090\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000916\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.012784\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001653\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001722\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000737\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.012193\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001486\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001247\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000719\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.011539\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000961\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000822\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000991\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.017187\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001481\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001165\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001011\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.021716\n",
            "GD: 0.4144214391708374, RD: 0.828709065914154, revKL: -40.09443664550781\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000867\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001444\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.003576\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.022976\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000717\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001983\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001340\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.015003\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001055\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001303\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000754\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.017228\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000981\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000951\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000551\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.016063\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001492\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001511\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000897\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.015426\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000850\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.001129\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.001029\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.014215\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001452\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001939\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000843\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.014235\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001767\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.001360\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000778\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.013064\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001480\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.001149\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.001144\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.012945\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001787\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001636\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000849\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.012449\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000971\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001248\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001253\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.012754\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001288\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001137\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000981\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.015765\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001763\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001934\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000936\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.015208\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001658\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001338\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000872\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.014815\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001042\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000982\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001203\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.022460\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001661\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001271\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001210\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.025684\n",
            "GD: 2.290865421295166, RD: 0.74247807264328, revKL: -41.24310302734375\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000165\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000385\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001506\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.009221\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000163\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000626\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000275\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.007532\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000292\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000273\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000148\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.008941\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000277\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000302\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000262\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.008918\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000339\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000624\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000264\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.006791\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000247\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000345\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000261\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.006799\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000441\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000583\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000216\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.005828\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000467\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000270\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000193\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.005250\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000331\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000247\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000200\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.005147\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000485\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000390\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000235\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.006177\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000429\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000557\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000397\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.006485\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000572\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000470\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000265\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.008103\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000563\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000566\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000495\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.008276\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000634\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000504\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000281\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.008059\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000519\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000485\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000416\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.011250\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000552\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000548\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000640\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.015531\n",
            "GD: 2.258997678756714, RD: 1.5603601932525635, revKL: -17.006916046142578\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000255\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000597\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001770\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.012316\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000273\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000896\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000941\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.009699\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000503\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000659\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000244\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.010269\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000506\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000506\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000381\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.010007\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000572\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000800\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000545\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.009540\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000524\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000688\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000470\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.009112\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000595\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000731\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000513\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.008881\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000952\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000582\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000501\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.008505\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000693\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000630\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000599\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.008175\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001148\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000893\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000993\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.009786\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000794\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000992\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000893\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.010980\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001434\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001083\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000726\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.011477\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001406\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001706\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001715\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.011483\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001274\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000896\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000684\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.010026\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001190\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000988\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000873\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.013294\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001532\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001038\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000894\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.015681\n",
            "GD: 1.793603539466858, RD: 1.4302898645401, revKL: -28.759441375732422\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000681\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001018\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002031\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.014368\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000575\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001566\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001250\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.011916\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000796\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000940\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000348\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.012792\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000667\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000658\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000412\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.012599\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000686\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000871\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000603\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.011678\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000811\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000834\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000629\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.011321\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001123\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001431\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000635\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.011808\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001681\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.001014\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000716\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.011180\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000937\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000832\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000913\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.010702\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001242\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000999\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.001555\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.011958\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001042\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001312\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001233\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.014081\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001832\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001317\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.001187\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.014565\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.002011\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.002424\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.002571\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.014773\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001671\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001413\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001175\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.013123\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001735\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001219\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001429\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.017259\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.002388\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001673\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001582\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.022872\n",
            "GD: 1.802747368812561, RD: 0.736815869808197, revKL: -38.59166717529297\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000735\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001102\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002098\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.015622\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000586\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001631\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001336\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.013640\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001002\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001106\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000336\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.014473\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000800\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000770\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000474\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.014160\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000762\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001012\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000712\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.013245\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000945\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000956\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000685\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.012553\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001416\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001806\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000727\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.013337\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.002173\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.001218\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000808\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.012513\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001003\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000886\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000958\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.011747\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001270\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001075\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.001626\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.012974\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001154\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001517\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001271\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.015377\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.002029\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001410\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.001137\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.016350\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.002450\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.002644\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.002642\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.016772\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001775\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001444\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001301\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.014912\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001932\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001311\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001482\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.019735\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.002424\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001909\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001687\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.026626\n",
            "GD: 5.101724624633789, RD: 2.005021095275879, revKL: -40.11363983154297\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000654\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001192\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001905\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.026793\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000552\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.002006\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001536\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.015768\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001477\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001292\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000449\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.014049\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.001411\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001109\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000579\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.013182\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001226\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001256\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000486\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.012490\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000747\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.001183\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000742\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.013091\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001431\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001071\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000501\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.011936\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001242\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000771\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000471\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.011245\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.002088\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000859\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000518\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.010857\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001330\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001066\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000603\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.012034\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001380\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001182\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000803\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.013558\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.002007\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001124\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000797\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.015290\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001740\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001210\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000806\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.016102\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001030\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000947\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000788\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.015278\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001941\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001121\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001176\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.021418\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001378\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000884\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001471\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.016340\n",
            "GD: 0.5008206367492676, RD: 0.938014805316925, revKL: -48.599159240722656\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000720\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001283\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002007\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.028273\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000606\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.002083\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001611\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.017722\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001541\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001368\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000508\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.016743\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.001463\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001176\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000869\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.016607\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001302\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001322\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000496\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.014572\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000770\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.001204\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000779\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.014928\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001748\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001770\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000625\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.013865\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001334\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000823\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000495\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.012940\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.002119\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000930\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000645\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.012386\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001490\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001237\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000669\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.013762\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001547\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001482\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001040\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.015351\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.002125\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001274\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000994\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.017699\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001887\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001306\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001156\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.018384\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001218\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001132\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001168\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.017688\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.002199\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001262\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001413\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.025293\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001581\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001040\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001995\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.026120\n",
            "GD: 0.7430907487869263, RD: 0.8521153330802917, revKL: -35.063560485839844\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000766\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001336\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002061\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.028333\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000649\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.002122\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001587\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.017823\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001572\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001383\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000513\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.016646\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.001503\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001252\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000882\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.016200\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001340\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001330\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000508\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.014568\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000801\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.001187\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000803\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.014851\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001691\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001726\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000611\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.014153\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001650\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000939\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000608\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.013142\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.002269\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.001043\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000713\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.012495\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001445\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001211\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000811\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.014043\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001633\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001561\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001179\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.015745\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.002150\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001327\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.001033\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.017715\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.002037\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001465\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001349\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.018248\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001277\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001195\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001134\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.017207\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.002353\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001447\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001447\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.024354\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001763\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001132\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001902\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.024029\n",
            "GD: 1.8299460411071777, RD: 1.833996057510376, revKL: -22.902584075927734\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.001266\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001900\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002900\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.031692\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.001059\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.002785\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.002138\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.021547\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001765\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001679\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000719\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.019416\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.001830\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001483\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.001089\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.018897\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001560\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001481\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000644\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.017968\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.001086\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.001452\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000974\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.018159\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001978\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.002285\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000774\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.017673\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.002297\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.001230\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000931\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.015853\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.002400\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.001334\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000919\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.014845\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001692\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001435\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.001036\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.016053\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001691\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001704\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001427\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.018465\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.002395\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001524\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.001255\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.021005\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.002146\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001903\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.002068\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.021592\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001788\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001543\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001200\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.021035\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.002873\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001720\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001878\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.028462\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.002767\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001956\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.002233\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.027555\n",
            "GD: 2.9669620990753174, RD: 1.0411101579666138, revKL: -53.099700927734375\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000591\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000842\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001417\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.011625\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000418\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001375\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000872\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.009976\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000778\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000812\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000391\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.009849\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000761\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000834\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000561\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.010467\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000667\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000741\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000366\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.008701\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000522\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000706\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000995\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.008567\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001256\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001199\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000379\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.006765\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000995\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000375\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000244\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.006332\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000468\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000323\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000206\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.005470\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000787\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000535\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000305\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.006627\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000801\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000884\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000486\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.007587\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000694\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000651\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000480\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.008708\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000912\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000804\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000762\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.008850\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000855\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000705\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000764\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.008543\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000746\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000582\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000784\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.012294\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000694\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000555\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001071\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.018666\n",
            "GD: 1.751670241355896, RD: 0.988078773021698, revKL: -46.48438262939453\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000655\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000925\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001785\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.013517\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000451\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001513\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001085\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.011637\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000861\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000857\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000498\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.012043\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000827\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000965\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000495\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.011136\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000697\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000796\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000397\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.009539\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000596\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000824\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000931\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.009508\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001656\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001824\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000526\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.007684\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001106\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000472\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000327\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.006982\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000522\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000412\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000297\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.006188\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000867\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000660\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000348\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.006993\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000964\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001002\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000509\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.008274\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000964\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000818\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000500\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.009327\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001048\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001099\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000908\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.009739\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000984\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000923\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000980\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.009447\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000981\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000720\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000719\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.013234\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000865\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000674\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000907\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.020033\n",
            "GD: 0.6661268472671509, RD: 1.1572141647338867, revKL: -36.985374450683594\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000793\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001193\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002271\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.018344\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000543\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001828\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001225\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.014390\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001041\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001109\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000544\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.015337\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000962\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001179\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000648\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.013536\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000927\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001174\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000405\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.012014\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000822\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000972\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000925\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.011979\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001832\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.002180\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000557\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.010089\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001228\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000647\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000312\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.009321\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000857\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000647\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000334\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.008491\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001084\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000990\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000553\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.008616\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000954\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001146\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000628\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.010015\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001235\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000963\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000553\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.011866\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001249\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001318\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000915\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.011935\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001062\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000989\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001042\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.011352\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001063\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000836\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000704\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.016011\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001109\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000879\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001042\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.024823\n",
            "GD: 2.342038869857788, RD: 1.8889042139053345, revKL: -19.921140670776367\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000843\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001489\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002445\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.021205\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000561\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.002059\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001381\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.016280\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001187\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001268\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000591\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.016477\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.001331\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001467\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000755\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.014977\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001037\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001476\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000608\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.014761\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.001080\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.001440\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.001271\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.014874\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.002000\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.002332\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000826\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.013408\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.002125\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.001089\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000653\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.012708\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001216\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.001048\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000616\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.011595\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001359\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001307\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.001353\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.011316\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001332\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001351\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001061\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.014457\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.002029\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001517\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000980\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.015951\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001551\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001790\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.002177\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.016252\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001737\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001478\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001133\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.014482\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001860\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001426\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001209\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.019892\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001837\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001259\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001277\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.024896\n",
            "GD: 2.241811752319336, RD: 1.8678276538848877, revKL: -44.178924560546875\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000335\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000600\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001457\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.010389\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000249\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000907\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000593\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.007918\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000434\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000451\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000260\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.008228\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000389\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000446\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000384\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.009072\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000555\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000829\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000346\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.008679\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000374\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000528\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000378\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.008395\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000768\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000832\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000224\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.006689\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000531\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000367\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000138\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.005894\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000468\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000346\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000174\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.005750\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000767\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000632\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000349\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.006360\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000474\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000528\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000201\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.006663\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000496\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000395\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000424\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.008652\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000747\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000581\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000381\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.008986\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000526\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000373\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000300\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.008782\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000618\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000476\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000617\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.013078\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000584\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000543\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000822\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.020330\n",
            "GD: 1.839233636856079, RD: 0.83065265417099, revKL: -36.105918884277344\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000386\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000690\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001641\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.012898\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000330\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001200\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000764\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.009589\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000661\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000588\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000289\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.009334\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000711\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000630\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000533\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.010324\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000911\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001041\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000564\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.009887\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000424\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000597\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000444\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.009509\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000923\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000974\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000298\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.007682\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000639\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000445\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000145\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.006816\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000587\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000498\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000204\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.006718\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000849\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000685\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000362\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.007192\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000672\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000693\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000301\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.007773\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000767\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000565\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000538\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.009882\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001000\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000693\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000702\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.010535\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000705\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000685\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000371\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.010288\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000844\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000699\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000636\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.015042\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000932\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000788\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000945\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.021034\n",
            "GD: 0.8998068571090698, RD: 1.5201717615127563, revKL: -35.96855163574219\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000436\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000817\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001872\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.015180\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000350\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001261\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000875\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.011696\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000685\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000613\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000311\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.012377\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000715\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000680\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000692\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.014180\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000932\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001124\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000606\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.012949\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000506\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000639\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000532\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.012367\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001367\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001463\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000446\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.010077\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000698\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000534\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000226\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.008784\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000665\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000602\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000243\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.008546\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000989\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000811\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000389\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.009282\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000709\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000749\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000439\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.010225\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000841\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000678\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000646\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.012986\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001070\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000813\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000914\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.014060\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000820\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000802\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000638\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.014128\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000972\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000869\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001028\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.020137\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001027\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000880\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001433\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.028027\n",
            "GD: 0.8171738982200623, RD: 1.2148683071136475, revKL: -42.85138702392578\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000522\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001026\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.003788\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.023723\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000406\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001573\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001063\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.019068\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000739\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000691\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000337\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.021315\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000780\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000797\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.001197\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.022426\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001076\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001309\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000690\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.018708\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000644\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000818\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000690\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.018340\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.002434\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.002644\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000728\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.015644\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000930\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000733\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000321\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.013422\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000808\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000765\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000344\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.013162\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001394\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001142\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000599\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.015055\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000777\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000988\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000657\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.016276\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000888\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000900\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000933\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.020376\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001186\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001178\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001459\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.022444\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001286\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001238\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001128\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.022359\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001294\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001055\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001817\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.032653\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001291\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001008\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.002319\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.049548\n",
            "GD: 0.9952810406684875, RD: 1.0078331232070923, revKL: -35.76026916503906\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000383\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000281\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001739\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.007899\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000135\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000413\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000164\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.003771\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000247\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000205\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000097\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.004160\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000214\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000275\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000190\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.004725\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000292\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000381\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000150\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.004692\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000163\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000188\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000155\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.004525\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000261\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000409\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000178\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.003993\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000308\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000234\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000119\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.003540\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000609\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000346\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000196\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.003526\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000280\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000285\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000144\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.003361\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000276\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000330\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000180\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.003590\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000246\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000244\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000171\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.004496\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000489\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000429\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000382\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.005039\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000299\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000344\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000278\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.005099\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000312\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000267\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000415\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.007786\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000402\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000344\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000588\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.010027\n",
            "GD: 1.7782738208770752, RD: 0.9018482565879822, revKL: -41.40193176269531\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000479\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000513\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002023\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.010576\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000246\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000610\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000581\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.007472\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000386\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000526\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000181\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.009328\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000355\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000439\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000490\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.009728\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000397\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000499\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000416\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.008031\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000281\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000425\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000285\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.007915\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000749\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001047\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000359\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.007272\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000553\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000369\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000260\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.006266\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000730\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000502\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000249\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.006070\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000655\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000601\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000365\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.006888\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000502\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000616\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000604\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.007724\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000611\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000510\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000444\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.008903\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000582\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000573\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000752\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.009866\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000650\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000613\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000529\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.010014\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000690\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000518\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001014\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.013592\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000685\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000530\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001050\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.019291\n",
            "GD: 0.4518774747848511, RD: 0.8765667080879211, revKL: -33.60020446777344\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000802\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001118\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.003003\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.017203\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000428\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001437\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000932\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.013962\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000995\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001076\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000404\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.017196\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000592\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000740\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000835\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.017127\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000856\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000978\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000623\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.014577\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000676\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000976\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000846\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.014539\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001506\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.002100\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000564\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.013344\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001119\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000782\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000360\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.012175\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000948\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000903\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000452\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.011467\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001177\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001046\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000703\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.012373\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000762\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000986\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001247\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.013989\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000889\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000888\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000775\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.016424\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001130\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001192\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001627\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.017209\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001135\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001013\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001218\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.017204\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001099\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000901\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001790\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.023254\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001397\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000990\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001804\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.030649\n",
            "GD: 0.6357331871986389, RD: 1.3746769428253174, revKL: -39.8328742980957\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000972\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001342\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.004224\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.021954\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000687\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001704\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000847\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.015344\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001453\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001445\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000572\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.018250\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000747\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000855\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000634\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.017908\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001023\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001114\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000786\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.016430\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000871\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.001015\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000937\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.015960\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001199\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001886\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000640\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.014327\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001651\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000964\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000565\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.013761\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001489\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.001018\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000603\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.012732\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001336\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001170\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000760\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.013565\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001255\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001422\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001083\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.014647\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001552\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001296\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000948\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.017137\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001756\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001464\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001728\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.018407\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001352\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001164\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001225\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.017828\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001183\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000962\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001634\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.025513\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.002268\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001333\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001806\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.031524\n",
            "GD: 0.5399426221847534, RD: 0.8984775543212891, revKL: -32.47799301147461\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000513\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000699\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.000988\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.009381\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000413\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001090\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000473\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.006331\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000458\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000546\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000272\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.007586\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000382\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000355\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000231\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.007807\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000496\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000570\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000190\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.007227\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000373\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000422\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000488\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.006666\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000879\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000924\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000412\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.006813\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000520\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000408\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000212\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.005951\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000533\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000397\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000181\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.005666\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000552\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000512\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000233\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.006032\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000422\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000445\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000286\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.006974\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000796\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000635\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000348\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.007720\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000676\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000783\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000565\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.007847\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000634\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000449\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000331\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.008275\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000685\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000601\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000695\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.010536\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000726\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000622\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001157\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.012752\n",
            "GD: 2.2202889919281006, RD: 0.8321110606193542, revKL: -48.72307586669922\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000504\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000846\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.007065\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.024965\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000439\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001428\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000912\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.012275\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000505\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000569\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000329\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.015649\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000442\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000447\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000519\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.014267\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000571\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000666\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000291\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.010161\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000441\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000523\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000481\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.009691\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001058\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001251\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000453\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.008766\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000711\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000525\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000367\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.008133\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000625\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000505\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000232\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.007834\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001279\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001145\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000449\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.009639\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001541\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001564\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000484\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.009094\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000855\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000793\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000435\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.010474\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000758\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000990\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000570\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.010929\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000776\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000574\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000248\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.011135\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000767\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000718\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000693\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.015449\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000844\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000780\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001026\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.021086\n",
            "GD: 2.2096123695373535, RD: 1.5231316089630127, revKL: -39.77610778808594\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000530\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001005\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.006973\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.025402\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000482\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001533\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001263\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.013671\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000739\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000789\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000397\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.016652\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000566\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000608\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000496\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.015795\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000802\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000876\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000350\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.012389\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000538\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000800\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000681\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.011625\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000984\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001276\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000477\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.010121\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001015\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000639\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000457\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.009670\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000766\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000590\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000301\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.009268\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001279\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001171\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000526\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.010924\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001658\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001753\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000536\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.011027\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001236\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001043\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000593\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.013082\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001189\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001194\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000734\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.013189\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000907\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000654\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000306\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.013535\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001107\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000966\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001027\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.018109\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001134\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000904\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001333\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.025546\n",
            "GD: 0.4164012670516968, RD: 0.7739675641059875, revKL: -34.13262176513672\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000612\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001177\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.007583\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.029010\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000563\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001798\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001514\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.015783\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000845\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000907\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000374\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.019170\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000667\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000733\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000405\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.018843\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000850\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001032\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000439\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.015421\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000624\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000988\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000882\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.015194\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001013\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001333\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000602\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.013270\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001204\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000750\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000652\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.012405\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000914\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000721\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000362\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.011851\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001334\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001256\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000664\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.013821\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001789\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001948\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000798\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.014450\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001314\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001283\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000743\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.016844\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001546\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001491\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001108\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.016726\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001187\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000908\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000953\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.017057\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001350\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001087\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001351\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.022913\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001475\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001074\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001853\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.033007\n",
            "GD_loss: 0.4164012670516968\n",
            "RD_loss: 0.7739675641059875\n",
            "revKL_loss: -34.13262176513672\n",
            "[1000] loss_combined=-15.88\n",
            "GD: 1.9419375658035278, RD: 0.6662821173667908, revKL: -18.57400131225586\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000433\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000584\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.000599\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.006569\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000223\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000637\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000506\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.005324\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000339\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000345\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000220\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.005661\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000442\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000434\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000212\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.004917\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000478\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000444\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000215\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.005423\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000315\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000380\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000441\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.005712\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000395\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000455\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000370\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.005859\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000828\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000512\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000360\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.005687\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000716\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000488\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000320\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.005576\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000965\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000725\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000629\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.007633\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000637\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000653\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000689\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.008638\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000710\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000566\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000531\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.007336\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000868\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000874\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000999\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.008502\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001618\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001017\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000247\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.007909\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001319\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000840\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000605\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.008015\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000590\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000549\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000348\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.005820\n",
            "GD: 2.31622576713562, RD: 1.1076030731201172, revKL: -21.86174201965332\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000465\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000758\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001065\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.009493\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000272\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000895\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000667\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.007056\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000434\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000473\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000305\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.007911\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000510\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000549\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000256\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.007486\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000602\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000586\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000332\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.007602\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000465\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000560\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000574\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.007595\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000711\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000853\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000529\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.007560\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001112\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000656\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000473\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.007400\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000855\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000624\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000423\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.007121\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001174\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000919\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000747\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.009370\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000855\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000792\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000901\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.010767\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000974\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000848\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000750\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.010070\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001477\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001407\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001483\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.011063\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001807\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001246\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000414\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.010864\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001527\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001064\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000920\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.011733\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000957\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000744\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000999\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.010662\n",
            "GD: 0.9218788146972656, RD: 1.2510979175567627, revKL: -42.299591064453125\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000755\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001300\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.003672\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.020136\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000511\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001840\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001296\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.012614\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000743\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000803\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000488\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.012384\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.001552\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001015\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000665\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.011576\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001092\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001004\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000393\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.010772\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000828\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000932\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000620\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.010459\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001308\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001050\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000644\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.010735\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001807\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000909\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000578\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.009936\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.002936\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.001104\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000552\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.009633\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001777\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001208\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000861\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.013494\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001477\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001559\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000941\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.015190\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001500\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001226\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000943\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.014935\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.002869\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001889\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001540\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.015543\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.002011\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001378\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000528\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.015143\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.003402\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001033\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001131\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.017977\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.002885\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001498\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001406\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.017320\n",
            "GD: 2.2259881496429443, RD: 1.583247184753418, revKL: -38.627872467041016\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000795\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001448\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.004261\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.024584\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000600\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001954\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001361\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.014889\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000974\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001055\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000672\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.014781\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.001669\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001215\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000682\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.014013\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001202\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001438\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000621\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.013318\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000892\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.001102\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000769\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.012719\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001336\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001168\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000787\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.012153\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001950\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.001012\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000664\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.011341\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.002917\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.001080\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000607\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.011080\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001958\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001450\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000882\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.015145\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001618\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001798\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001103\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.017198\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.002119\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001530\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.001188\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.017691\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.003285\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.002004\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001554\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.017727\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.002233\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001546\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000721\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.017084\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.003634\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001341\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001238\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.020758\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.003016\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001874\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001613\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.020967\n",
            "GD: 1.8406083583831787, RD: 0.8449319005012512, revKL: -37.839603424072266\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000431\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000510\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001117\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.007113\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000196\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000731\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000291\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.004670\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000333\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000383\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000153\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.004441\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000247\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000279\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000156\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.004511\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000227\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000363\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000176\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.004750\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000281\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000372\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000235\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.004469\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000410\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000402\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000234\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.003848\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000529\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000259\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000258\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.003569\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000334\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000215\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000137\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.003394\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000467\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000487\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000331\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.004266\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000404\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000409\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000300\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.005002\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000571\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000309\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000432\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.005329\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000791\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000604\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000595\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.005463\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000618\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000393\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000212\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.005480\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000554\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000461\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000498\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.007640\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000739\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000669\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000468\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.008272\n",
            "GD: 0.2800244688987732, RD: 0.9509798288345337, revKL: -48.3008918762207\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000553\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000782\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001835\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.012473\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000320\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001253\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000482\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.009559\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000453\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000742\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000446\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.009847\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000453\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000458\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000488\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.008871\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000458\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000652\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000353\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.007930\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000375\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000468\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000418\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.007792\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000920\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001044\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000493\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.007007\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000682\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000379\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000486\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.006431\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000509\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000374\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000234\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.006217\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000749\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000635\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000454\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.007075\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000570\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000711\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000590\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.007990\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000727\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000458\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000596\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.009751\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000960\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000878\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000758\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.009610\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000849\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000648\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000421\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.009442\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000740\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000536\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000797\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.012757\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000811\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000850\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001060\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.016756\n",
            "GD: 0.9497907161712646, RD: 0.4884825646877289, revKL: -45.30734634399414\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000748\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000965\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002141\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.015480\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000364\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001439\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000555\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.012136\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000590\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000827\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000517\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.012938\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000521\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000593\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000592\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.012230\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000535\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000746\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000326\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.010701\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000434\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000564\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000495\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.010796\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000901\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001157\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000583\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.009379\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000773\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000433\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000555\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.008589\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000603\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000472\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000234\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.008352\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000755\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000651\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000471\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.009628\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000667\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000814\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000851\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.010340\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000823\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000620\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000736\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.013548\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001086\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001061\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001056\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.013659\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001001\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000769\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000525\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.013373\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000952\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000691\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001081\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.018484\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001335\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001073\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001391\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.024111\n",
            "GD: 2.2373812198638916, RD: 2.5166983604431152, revKL: -23.43697738647461\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000885\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001170\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002671\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.019066\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000507\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.002015\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001183\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.014739\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001060\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001188\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000586\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.014010\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000889\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000946\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000524\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.013687\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000835\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001110\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000632\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.012440\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000668\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000972\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000904\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.012743\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001399\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001361\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000829\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.011354\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001090\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000824\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000756\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.010510\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001241\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000926\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000675\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.009704\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001797\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001650\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.001270\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.012687\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001963\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001964\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001230\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.013593\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001316\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001241\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000836\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.014471\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001225\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.002295\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001422\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.013618\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001300\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001143\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000469\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.012948\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000993\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000893\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000940\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.017247\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001542\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001464\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001304\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.022186\n",
            "GD: 0.3195607662200928, RD: 1.2156836986541748, revKL: -17.61943817138672\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000322\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000440\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.000486\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.005025\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000176\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000492\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000334\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.003425\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000404\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000417\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000146\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.004225\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000348\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000361\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000142\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.004105\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000487\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000509\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000203\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.003897\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000282\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000363\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000216\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.003755\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000377\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000478\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000226\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.003999\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000524\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000303\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000215\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.003535\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000452\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000353\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000149\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.003203\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000461\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000401\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000232\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.003445\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000347\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000358\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000208\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.003859\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000378\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000367\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000385\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.004182\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000512\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000668\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000379\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.004442\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000610\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000403\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000137\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.004408\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000406\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000386\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000323\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.005049\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000565\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000535\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000304\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.004787\n",
            "GD: 1.3748583793640137, RD: 1.0945873260498047, revKL: -46.34951400756836\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000588\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000853\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001245\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.012336\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000382\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000997\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000554\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.009018\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000774\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000610\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000396\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.009525\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000694\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000709\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000374\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.008986\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000837\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000859\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000332\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.008453\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000646\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000558\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000365\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.008835\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000848\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000898\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000354\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.008015\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000947\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000584\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000292\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.007660\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001236\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000754\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000448\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.007152\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000916\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000741\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000339\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.007321\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000895\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000845\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000543\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.007806\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000677\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000619\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000597\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.009726\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001043\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001000\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000608\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.010527\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001300\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000886\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000579\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.010722\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001000\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000700\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001038\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.014547\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001357\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001451\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000759\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.015992\n",
            "GD: 1.760196566581726, RD: 1.4224966764450073, revKL: -59.19257736206055\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.001132\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001730\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.013591\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.049728\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000663\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.002453\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001718\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.030876\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000980\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000791\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000545\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.038367\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000944\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001166\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.001447\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.033950\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001000\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001217\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000600\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.024040\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000823\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000860\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000707\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.023733\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.002166\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.002726\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000781\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.019052\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001271\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000815\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000539\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.017546\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001420\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.001016\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000584\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.016720\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001223\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001086\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.001015\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.021012\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001193\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001633\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.002132\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.022072\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001089\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000921\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.001111\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.031071\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001508\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001463\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001741\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.032354\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001431\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001242\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001867\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.032755\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.002035\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000999\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.002673\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.047917\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001961\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001898\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.002844\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.054639\n",
            "GD: 2.432332992553711, RD: 0.6905964612960815, revKL: -44.12049865722656\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.001104\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001777\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.012995\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.046803\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000703\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.002397\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001644\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.029208\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001148\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000922\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000536\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.036571\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.001065\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001184\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.001216\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.032334\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001059\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001277\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000654\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.023129\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000907\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000988\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000713\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.022871\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001592\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.002200\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000830\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.018599\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001537\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000964\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000561\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.016957\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001541\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.001138\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000692\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.016787\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001378\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001220\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.001032\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.020933\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001285\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001722\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.002044\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.022057\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001265\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001123\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.001161\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.029592\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001831\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001744\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001585\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.030773\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001856\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001487\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001421\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.031503\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.002239\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001742\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.002609\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.045572\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.002110\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001926\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.002583\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.053091\n",
            "GD: 2.4308829307556152, RD: 1.127984642982483, revKL: -43.88493347167969\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000302\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000709\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001824\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.013505\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000246\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000962\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000759\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.007948\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000609\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000471\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000291\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.008585\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000593\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000510\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000198\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.008601\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000642\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000609\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000357\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.007038\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000374\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000434\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000385\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.006666\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000746\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000855\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000269\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.006048\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000535\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000340\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000161\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.005575\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000858\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000408\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000263\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.005334\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000786\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000668\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000374\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.006010\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000556\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000592\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000253\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.006491\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000833\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000528\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000366\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.007785\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000757\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001019\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000376\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.009414\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000714\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000711\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000287\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.009041\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000629\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000634\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000718\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.012702\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001184\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000890\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001049\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.016509\n",
            "GD: 1.5739681720733643, RD: 1.3144739866256714, revKL: -25.716001510620117\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000602\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001299\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002276\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.019506\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000665\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001675\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000956\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.012401\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000816\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000786\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000569\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.013292\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.001902\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001022\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000368\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.011465\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001000\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000911\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000518\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.010511\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.001068\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000796\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000552\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.010351\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000818\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001012\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000412\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.009441\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001139\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000792\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000511\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.009437\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001309\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000659\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000547\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.008982\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001433\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001308\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000652\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.009752\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001140\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001223\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000562\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.010895\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001448\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000960\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000797\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.012542\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001539\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001488\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000895\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.012594\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001528\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001089\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000362\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.012928\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001588\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001365\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001182\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.016291\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.003387\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001896\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001885\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.018638\n",
            "GD: 0.5354001522064209, RD: 0.7385298609733582, revKL: -34.57882308959961\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000616\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001344\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002651\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.020699\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000674\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001766\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000988\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.012730\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000841\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000874\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000612\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.013732\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.001927\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001080\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000405\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.011851\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001016\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000968\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000531\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.010783\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.001084\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000890\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000552\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.010503\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000861\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001101\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000434\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.009526\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001144\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000819\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000437\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.009632\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001325\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000677\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000543\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.009120\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001415\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001262\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000660\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.009986\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001204\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001285\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000575\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.011204\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001488\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000990\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000753\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.012626\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001592\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001568\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000831\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.012702\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001572\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001106\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000521\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.013067\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001664\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001380\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001255\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.016511\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.003401\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.002007\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001901\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.018201\n",
            "GD: 3.60504150390625, RD: 0.8340259790420532, revKL: -45.806541442871094\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000834\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001751\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.003454\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.029416\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.001041\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.002643\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001363\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.018552\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001106\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001172\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000587\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.018906\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.002144\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001438\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000477\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.016408\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001421\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001302\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000696\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.015836\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.001420\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.001405\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000819\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.016654\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001083\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001441\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000523\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.014784\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001370\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000930\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000468\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.014607\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001906\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000920\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000624\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.013944\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001857\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001871\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000850\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.015323\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001444\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001462\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000967\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.017563\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001937\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001419\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000980\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.019052\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001868\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.002189\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000951\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.020495\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001892\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001481\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000826\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.021335\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.002059\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001421\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001645\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.028229\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.003873\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.002302\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.003203\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.025587\n",
            "GD: 0.8381744623184204, RD: 0.6744107604026794, revKL: -27.199329376220703\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000362\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000521\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.000861\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.009021\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000304\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000657\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000416\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.007128\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000874\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000477\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000146\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.007857\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000706\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000641\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000210\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.007842\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000856\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000532\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000238\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.006310\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000605\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000443\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000361\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.006367\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000695\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000966\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000569\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.006356\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000933\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000345\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000432\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.005854\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000804\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000431\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000278\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.005418\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000730\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000658\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000584\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.006346\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000787\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000856\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000614\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.006838\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000942\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000708\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000811\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.007256\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001011\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000974\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001406\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.007247\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001013\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000561\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000408\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.007006\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001876\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000632\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000813\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.008094\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.002158\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000794\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000992\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.010211\n",
            "GD: 1.843605637550354, RD: 0.7593860626220703, revKL: -60.91426086425781\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000546\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001098\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.009119\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.035358\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000506\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001709\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001150\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.028079\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000957\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000584\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000385\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.029503\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000846\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000790\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.001089\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.028362\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000953\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000724\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000459\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.020675\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000752\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000699\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000657\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.020054\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.002225\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.002662\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.001039\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.017143\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001165\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000585\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000633\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.015085\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000912\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000515\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000442\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.014926\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001546\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001203\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.001076\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.019571\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000939\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001253\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001689\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.020653\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001111\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000810\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.001244\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.027515\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001787\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001507\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.002480\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.028551\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001372\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000983\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001601\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.029578\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.002209\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000923\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.002493\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.039257\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.002292\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001052\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.002862\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.048342\n",
            "GD: 1.083655834197998, RD: 0.9752009510993958, revKL: -34.6533203125\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000707\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001347\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.009259\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.037466\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000544\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001867\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001129\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.028743\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001071\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000743\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000420\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.029749\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000927\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000922\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.001035\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.028054\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001004\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000871\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000576\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.020993\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000806\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000755\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000674\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.020292\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.002128\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.002655\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.001118\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.017675\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001386\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000776\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000808\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.015426\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001265\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000720\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000459\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.015239\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001732\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001423\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.001145\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.019791\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001061\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001359\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001514\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.020735\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001256\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000933\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.001340\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.027430\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001988\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001619\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.002311\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.028583\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001441\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001022\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001412\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.030022\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.002174\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000987\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.002557\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.039794\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.002963\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001288\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.002920\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.047798\n",
            "GD: 0.6459903717041016, RD: 0.6832047700881958, revKL: -39.5028076171875\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000717\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001344\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.008661\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.032936\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000575\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001788\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001168\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.026092\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001148\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000775\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000448\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.026307\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000942\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000956\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000778\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.024326\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001036\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000919\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000535\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.018532\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000824\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000743\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000648\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.017799\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001619\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.002193\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.001036\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.015781\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001416\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000779\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000785\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.013908\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001296\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000769\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000502\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.013700\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001571\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001353\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.001130\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.017706\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001080\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001282\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001377\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.018462\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001342\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000972\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.001271\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.023845\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001865\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001514\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.002046\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.024862\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001425\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001014\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001067\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.026586\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.002174\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001045\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.002228\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.033700\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.003013\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001342\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.002600\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.041003\n",
            "GD: 1.0925475358963013, RD: 1.3661580085754395, revKL: -37.92357635498047\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000418\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000545\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.000810\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.007381\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000219\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000636\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000321\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.004290\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000348\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000320\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000284\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.004639\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000296\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000269\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000174\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.004790\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000389\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000340\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000156\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.004730\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000301\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000296\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000229\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.004759\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000404\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000448\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000172\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.004350\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000414\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000196\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000146\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.003855\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000447\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000282\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000109\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.003613\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000335\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000286\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000169\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.003791\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000386\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000314\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000248\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.004231\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000464\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000325\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000410\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.005547\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000589\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000491\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000473\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.005404\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000443\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000337\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000221\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.005366\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000787\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000313\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000455\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.007237\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001116\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000532\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000487\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.009902\n",
            "GD: 0.6017811298370361, RD: 0.598859965801239, revKL: -47.800048828125\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000462\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000624\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002070\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.012105\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000242\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000791\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000496\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.008040\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000378\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000393\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000289\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.009465\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000343\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000339\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000242\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.009402\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000484\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000439\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000257\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.007391\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000337\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000345\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000305\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.007178\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000739\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000880\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000291\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.006529\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000437\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000225\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000194\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.005784\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000587\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000382\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000152\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.005576\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000472\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000450\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000406\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.006423\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000508\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000585\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000392\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.006763\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000643\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000503\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000660\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.008990\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000885\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000789\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000642\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.009668\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000707\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000581\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000338\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.009286\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000870\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000446\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000755\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.013490\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001061\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000511\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000958\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.019786\n",
            "GD: 2.2332403659820557, RD: 1.0994476079940796, revKL: -40.30949401855469\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000549\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000842\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002339\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.014643\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000353\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001258\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000752\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.010132\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000645\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000648\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000420\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.010329\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000549\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000487\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000289\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.010618\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000722\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000965\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000347\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.009317\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000424\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000444\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000404\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.008873\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000597\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000654\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000367\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.007683\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000683\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000351\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000352\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.006849\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000662\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000434\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000204\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.006416\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000780\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000691\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000380\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.007271\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000606\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000714\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000380\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.007775\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000806\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000639\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000708\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.010201\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001165\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001027\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000671\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.011002\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000721\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000682\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000536\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.011273\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001034\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000598\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000675\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.016555\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001474\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000891\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001002\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.021744\n",
            "GD: 2.4663121700286865, RD: 1.314530611038208, revKL: -42.17224884033203\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000808\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001290\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.003966\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.023249\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000453\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001699\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001343\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.016520\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001140\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001035\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000787\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.016841\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000777\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000827\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000750\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.017539\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000858\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001239\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000502\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.014657\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000695\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000708\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000710\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.014636\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001596\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001678\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000676\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.012679\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000760\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000513\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000498\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.011834\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000853\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000635\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000424\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.010394\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001382\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001248\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000457\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.013401\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001003\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001234\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000750\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.016769\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001504\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001212\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.001299\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.017887\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001901\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001589\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001151\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.018355\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001055\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000956\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001311\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.018874\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001752\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001546\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001636\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.027360\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001632\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001441\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001617\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.031180\n",
            "GD: 0.6549678444862366, RD: 1.1164134740829468, revKL: -44.052734375\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000541\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000625\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002394\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.013021\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000265\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001070\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000531\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.007630\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000511\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000787\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000273\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.007583\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000354\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000468\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000375\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.006745\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000683\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000545\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000364\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.005548\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000516\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000487\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000412\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.005259\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000368\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000638\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000315\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.005082\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000268\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000310\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000347\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.004408\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000550\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000417\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000221\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.004278\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000670\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000534\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000318\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.004469\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000580\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000668\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000220\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.004969\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000564\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000360\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000375\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.005689\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000865\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000585\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000338\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.005787\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000462\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000303\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000190\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.005909\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000797\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000518\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000523\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.008877\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000867\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000559\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000525\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.010231\n",
            "GD: 2.3892641067504883, RD: 1.3990285396575928, revKL: -39.68425750732422\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000644\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000950\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.005228\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.024201\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000365\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001758\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000925\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.014257\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000632\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000881\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000368\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.015330\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000456\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000636\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000576\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.013766\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000768\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000826\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000508\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.011757\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000603\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000696\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000457\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.010612\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001113\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001457\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000490\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.009112\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000505\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000373\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000443\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.008047\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000736\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000531\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000316\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.007745\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001118\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000982\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000569\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.009809\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000871\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001039\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000829\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.010806\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000898\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000535\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000583\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.013179\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001072\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000979\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001045\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.013972\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000659\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000585\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000782\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.014420\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001077\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000734\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001135\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.020572\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000937\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000761\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001344\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.023751\n",
            "GD: 0.8766584396362305, RD: 1.4095796346664429, revKL: -40.914833068847656\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000670\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000941\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.004964\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.023384\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000386\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001831\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001026\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.014377\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000674\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000905\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000351\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.015266\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000493\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000721\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000578\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.013936\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000812\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000983\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000473\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.012173\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000606\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000740\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000490\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.010842\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000726\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001302\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000468\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.009661\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000543\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000401\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000545\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.008449\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000879\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000647\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000362\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.008337\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001182\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001096\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000490\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.010429\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001075\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001247\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000819\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.011326\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000966\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000686\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000563\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.014082\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001165\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001027\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000983\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.014795\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000717\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000679\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000682\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.015213\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001197\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000845\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001158\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.022240\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001051\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000856\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001318\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.023751\n",
            "GD: 2.2578189373016357, RD: 2.5947344303131104, revKL: -47.04383850097656\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000795\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001114\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.005159\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.023884\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000437\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001935\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001166\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.014951\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000740\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001100\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000429\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.015734\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000636\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000875\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000423\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.014880\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000890\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001003\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000423\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.013156\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000660\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000826\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000534\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.011900\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000658\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001174\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000463\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.010394\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000664\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000465\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000536\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.009339\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001028\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000758\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000456\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.009237\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001349\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001265\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000601\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.011239\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001407\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001489\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000702\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.011994\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001093\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000898\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000663\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.014603\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001372\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001203\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000924\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.015094\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000915\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000902\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000489\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.015336\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001472\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001079\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000940\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.022488\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001433\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001081\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001082\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.023493\n",
            "GD: 1.7590808868408203, RD: 1.0226513147354126, revKL: -53.62618637084961\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000234\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000396\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.001484\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.007262\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000252\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000535\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000331\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.007024\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000261\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000292\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000090\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.006772\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000302\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000283\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000308\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.006471\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000294\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000473\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000295\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.005322\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000200\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000282\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000285\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.005004\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000511\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000833\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000278\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.004966\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000603\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000289\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000238\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.004250\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000587\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000425\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000168\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.003885\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000809\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000650\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000228\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.004727\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000397\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000439\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000230\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.004921\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000472\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000422\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000376\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.006205\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000786\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000715\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000428\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.007023\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000775\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000631\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000280\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.007077\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000632\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000485\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000430\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.008922\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000616\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000566\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000571\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.013830\n",
            "GD: 0.9778862595558167, RD: 0.7189249992370605, revKL: -32.49284362792969\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000315\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000570\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002820\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.013931\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000284\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.000862\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000485\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.011699\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000383\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000359\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000139\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.013398\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000357\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000367\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000716\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.013719\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000387\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000597\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000335\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.010279\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000327\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000480\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000326\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.010340\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001098\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001349\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000405\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.009106\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000707\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000390\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000299\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.007961\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000761\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000621\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000334\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.007276\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000870\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000753\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000411\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.008945\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000487\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000670\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000582\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.009341\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000517\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000483\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000474\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.012058\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000844\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000917\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001020\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.013009\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000856\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000716\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000767\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.013599\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000731\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000522\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001105\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.018737\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000674\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000663\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000993\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.026201\n",
            "GD: 0.8936343789100647, RD: 0.777565062046051, revKL: -35.482276916503906\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000401\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000704\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.005236\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.023768\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000362\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001384\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000924\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.017047\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000474\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000464\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000222\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.018780\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000466\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000547\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.001047\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.017757\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000499\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000728\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000383\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.013201\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000417\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000694\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000390\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.013205\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001442\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001822\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000494\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.011528\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000793\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000475\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000382\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.010072\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000928\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000825\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000456\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.009329\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001072\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001004\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000506\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.011293\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000572\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000852\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000948\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.011867\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000690\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000587\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000550\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.015771\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000955\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001059\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001413\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.016787\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000969\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000823\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001092\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.017325\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000922\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000577\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001608\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.024475\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.000861\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000778\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001391\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.031655\n",
            "GD: 1.7715098857879639, RD: 1.551116704940796, revKL: -39.8712158203125\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.002401\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.002559\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.006296\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.029583\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.001764\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.003712\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.002162\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.021677\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001301\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001146\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000428\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.021550\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000796\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000981\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.001345\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.021030\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000715\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001049\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000410\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.016214\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000649\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000950\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000639\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.016097\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001729\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.002077\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000585\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.013565\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001251\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000673\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000586\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.012102\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001173\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000954\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000535\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.010986\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001248\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001173\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000870\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.013553\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000858\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001129\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.001070\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.014107\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.001047\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000818\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000803\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.018761\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.001587\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001312\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.001661\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.019598\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.001499\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001088\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.001269\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.019723\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001552\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001018\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001546\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.027317\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001563\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001309\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001762\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.035275\n",
            "GD: 0.23322030901908875, RD: 0.8297996520996094, revKL: -38.870033264160156\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000499\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000650\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002415\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.013190\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000328\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001099\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000662\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.007358\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000358\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000483\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000183\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.007530\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000419\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000317\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000276\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.006629\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000405\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000524\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000235\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.005998\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000305\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000317\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000460\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.005679\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000673\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000714\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000166\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.004938\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000509\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000250\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000333\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.004818\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000445\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000281\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000217\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.004297\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000511\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000549\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000476\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.004464\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000398\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000483\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000498\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.004640\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000401\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000327\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000404\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.005969\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000619\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000431\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000670\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.006187\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000320\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000271\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000357\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.005927\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000709\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000408\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000858\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.008288\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001708\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000804\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000758\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.010228\n",
            "GD: 0.6118418574333191, RD: 0.7740484476089478, revKL: -37.18360900878906\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.000530\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.000661\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.002585\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.014409\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000378\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.001083\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.000621\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.008261\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.000462\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.000488\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000192\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.009133\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.000519\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.000495\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000280\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.008146\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.000474\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000608\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000259\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.006972\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000328\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000352\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000395\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.006588\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.000798\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.000850\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000191\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.005695\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.000544\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000278\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000308\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.005422\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.000506\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000362\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000212\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.004930\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.000457\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.000524\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.000478\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.005313\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.000474\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.000597\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.000697\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.005579\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.000496\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.000417\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.000590\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.007237\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.000776\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.000575\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.000754\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.007618\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.000379\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.000371\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000444\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.007609\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.000931\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.000515\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.000905\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.010623\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.001639\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.000853\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.000929\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.014031\n",
            "GD: 1.949781060218811, RD: 0.912038266658783, revKL: -41.13173294067383\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.001074\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001416\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.003369\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.022489\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000703\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.002169\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001356\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.017104\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001208\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001105\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000459\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.015827\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.001025\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001128\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000481\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.014740\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001056\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.000966\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000505\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.013038\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000699\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000849\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000715\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.012937\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001159\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001185\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000992\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.012004\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001645\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000621\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000787\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.010731\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001273\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000736\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000360\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.010125\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001448\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001160\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.001705\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.013450\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001013\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001018\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.002305\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.014687\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.002166\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001052\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.002097\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.016122\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.002718\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001741\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.002800\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.017571\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.003498\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001026\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000887\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.015268\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001737\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001137\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001332\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.018304\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.002446\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001229\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001536\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.019564\n",
            "GD: 2.2163052558898926, RD: 0.6002012491226196, revKL: -24.055461883544922\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight grad mean 0.001105\n",
            "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight grad mean 0.001483\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight grad mean 0.003833\n",
            "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight grad mean 0.024667\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight grad mean 0.000722\n",
            "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight grad mean 0.002395\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight grad mean 0.001508\n",
            "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight grad mean 0.018455\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight grad mean 0.001348\n",
            "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight grad mean 0.001218\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight grad mean 0.000506\n",
            "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight grad mean 0.017567\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight grad mean 0.001125\n",
            "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight grad mean 0.001201\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight grad mean 0.000483\n",
            "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight grad mean 0.016694\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight grad mean 0.001226\n",
            "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight grad mean 0.001035\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight grad mean 0.000517\n",
            "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight grad mean 0.014258\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight grad mean 0.000763\n",
            "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight grad mean 0.000926\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight grad mean 0.000759\n",
            "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight grad mean 0.014108\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight grad mean 0.001216\n",
            "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight grad mean 0.001412\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight grad mean 0.000990\n",
            "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight grad mean 0.013048\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight grad mean 0.001658\n",
            "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight grad mean 0.000697\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight grad mean 0.000926\n",
            "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight grad mean 0.011653\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight grad mean 0.001569\n",
            "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight grad mean 0.000997\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight grad mean 0.000412\n",
            "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight grad mean 0.011263\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight grad mean 0.001541\n",
            "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight grad mean 0.001279\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight grad mean 0.001585\n",
            "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight grad mean 0.014432\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight grad mean 0.001163\n",
            "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight grad mean 0.001214\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight grad mean 0.002278\n",
            "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight grad mean 0.016773\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight grad mean 0.002507\n",
            "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight grad mean 0.001314\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight grad mean 0.002037\n",
            "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight grad mean 0.017456\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight grad mean 0.002716\n",
            "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight grad mean 0.001705\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight grad mean 0.002471\n",
            "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight grad mean 0.018131\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight grad mean 0.003519\n",
            "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight grad mean 0.001132\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight grad mean 0.000892\n",
            "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight grad mean 0.016510\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight grad mean 0.001788\n",
            "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight grad mean 0.001169\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight grad mean 0.001340\n",
            "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight grad mean 0.020272\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight grad mean 0.002415\n",
            "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight grad mean 0.001263\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight grad mean 0.001752\n",
            "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight grad mean 0.022121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = model.merge_and_unload()\n",
        "model.save_pretrained(\"tmp/unlearned_8bit\", from_pt=True)"
      ],
      "metadata": {
        "id": "kKBdJGa6hFIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_save_dir=\"semeval25-unlearning-model\"\n",
        "# # 2) Ricarica da disco in FP32\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"tmp/unlearned_8bit\",\n",
        "    torch_dtype=torch.float32,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "model.save_pretrained(model_save_dir, from_pt=True)\n",
        "\n",
        "\n",
        "pretrained_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"semeval25-unlearning-1B-model\",\n",
        "    torch_dtype=torch.float32\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "PjxHVXilrIQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "26pkbHo7veyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(model_save_dir, from_pt=True)\n"
      ],
      "metadata": {
        "id": "QVz2wBFls-8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pretrained_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"semeval25-unlearning-1B-model\",\n",
        "    torch_dtype=torch.float32\n",
        ").to(device)\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "ZcsCuKolsqf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traskvector"
      ],
      "metadata": {
        "id": "k9aMEqf6rYrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "class TaskVector():\n",
        "    def __init__(self, pretrained_checkpoint=None, finetuned_checkpoint=None, vector=None):\n",
        "        \"\"\"Initializes the task vector from a pretrained and a finetuned checkpoints.\n",
        "\n",
        "        This can either be done by passing two state dicts (one corresponding to the\n",
        "        pretrained model, and another to the finetuned model), or by directly passying in\n",
        "        the task vector state dict.\n",
        "        \"\"\"\n",
        "        if vector is not None:\n",
        "            self.vector = vector\n",
        "        else:\n",
        "            assert pretrained_checkpoint is not None and finetuned_checkpoint is not None\n",
        "            with torch.no_grad():\n",
        "\n",
        "                pretrained_state_dict = pretrained_checkpoint.state_dict()\n",
        "                finetuned_state_dict = finetuned_checkpoint.state_dict()\n",
        "\n",
        "                self.vector = {}\n",
        "                for key in pretrained_state_dict:\n",
        "                    if pretrained_state_dict[key].dtype in [torch.int64, torch.uint8]:\n",
        "                        continue\n",
        "\n",
        "\n",
        "    def __add__(self, other):\n",
        "        \"\"\"Add two task vectors together.\"\"\"\n",
        "        with torch.no_grad():\n",
        "            new_vector = {}\n",
        "            for key in self.vector:\n",
        "                if key not in other.vector:\n",
        "                    print(f'Warning, key {key} is not present in both task vectors.')\n",
        "                    continue\n",
        "                new_vector[key] = self.vector[key] + other.vector[key]\n",
        "        return TaskVector(vector=new_vector)\n",
        "\n",
        "    def __radd__(self, other):\n",
        "        if other is None or isinstance(other, int):\n",
        "            return self\n",
        "        return self.__add__(other)\n",
        "\n",
        "    def __neg__(self):\n",
        "        \"\"\"Negate a task vector.\"\"\"\n",
        "        with torch.no_grad():\n",
        "            new_vector = {}\n",
        "            for key in self.vector:\n",
        "                new_vector[key] = - self.vector[key]\n",
        "        return TaskVector(vector=new_vector)\n",
        "\n",
        "    def apply_to(self, pretrained_model, scaling_coef=1.0):\n",
        "        \"\"\"Apply a task vector to a pretrained model.\"\"\"\n",
        "        with torch.no_grad():\n",
        "            new_state_dict = {}\n",
        "            pretrained_state_dict = pretrained_model.state_dict()\n",
        "            for key in pretrained_state_dict:\n",
        "                if key not in self.vector:\n",
        "                    print(f'Warning: key {key} is present in the pretrained state dict but not in the task vector')\n",
        "                    continue\n",
        "                new_state_dict[key] = pretrained_state_dict[key] + scaling_coef * self.vector[key]\n",
        "        pretrained_model.load_state_dict(new_state_dict, strict=False)\n",
        "        return pretrained_model\n",
        "\n",
        "\n",
        "    # You can uncomment the following version if you don't have enough GPU memory to apply the task vector in one go\n",
        "    # Split and reassemble the task vector using multiple chunks\n",
        "\n",
        "    # def apply_to(self, pretrained_model, scaling_coef=1.0, chunk_size=500):\n",
        "    #     \"\"\"Apply a task vector to a pretrained model in chunks.\"\"\"\n",
        "    #     with torch.no_grad():\n",
        "    #         pretrained_state_dict = pretrained_model.state_dict()\n",
        "    #         keys = list(self.vector.keys())  # Get all the parameter keys in the task vector\n",
        "    #         total_keys = len(keys)\n",
        "    #         for i in range(0, total_keys, chunk_size):\n",
        "    #             new_state_dict = {}\n",
        "    #             for key in keys[i:i + chunk_size]:\n",
        "    #                 if key not in pretrained_state_dict:\n",
        "    #                     print(f'Warning: key {key} is present in the task vector but not in the pretrained model')\n",
        "    #                     continue\n",
        "    #                 # Apply scaling and update the parameter\n",
        "    #                 new_state_dict[key] = pretrained_state_dict[key] + scaling_coef * self.vector[key]\n",
        "    #\n",
        "    #             # Partially load the updated state dict to the model\n",
        "    #             pretrained_model.load_state_dict(new_state_dict, strict=False)\n",
        "    #     return pretrained_model"
      ],
      "metadata": {
        "id": "z5EnH9bPfnyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task Vector\n",
        "task_vector_saving_path = \"semeval25-unlearning-model/task_vector\"\n",
        "task_vector= TaskVector(pretrained_model, model)\n",
        "neg_task_vector = -task_vector\n",
        "unlearned_model = neg_task_vector.apply_to(pretrained_model, scaling_coef=2.0)\n",
        "unlearned_model.save_pretrained(task_vector_saving_path, from_pt = True)\n"
      ],
      "metadata": {
        "id": "zrFTUNKezjdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "s8p6mIKUsYcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = \"cuda\"\n",
        "pretrained_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"semeval25-unlearning-1B-model\",\n",
        "    torch_dtype=torch.float32\n",
        ").to(device)\n",
        "\n",
        "unlearned_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"semeval25-unlearning-model/task_vector\",\n",
        "    torch_dtype = torch.float32\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "TbkOU7bjv7BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def eval_loss(model, dataloader, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_tokens = 0\n",
        "    loss_fct = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id, reduction=\"sum\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Eval\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attn      = batch[\"attention_mask\"].to(device)\n",
        "            labels    = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attn)\n",
        "            # logits: [B, L, V]\n",
        "            shift_logits = outputs.logits[:, :-1, :].contiguous()\n",
        "            shift_labels = labels[:, 1:].contiguous()\n",
        "\n",
        "            # flatten\n",
        "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)),\n",
        "                            shift_labels.view(-1))\n",
        "            total_loss += loss.item()\n",
        "            total_tokens += (shift_labels != tokenizer.pad_token_id).sum().item()\n",
        "\n",
        "    avg_nll = total_loss / total_tokens\n",
        "    ppl = torch.exp(torch.tensor(avg_nll))\n",
        "    return avg_nll, ppl.item()\n"
      ],
      "metadata": {
        "id": "ArfbaCQBscQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/OLMo-1B-0724-hf\")\n",
        "\n",
        "def tokenize_with_start(example):\n",
        "    q, a = example[\"input\"], example[\"output\"]\n",
        "    prefix = q\n",
        "    full   = q + a\n",
        "\n",
        "    # 1) tokenizza solo per contare i token reali (no pad)\n",
        "    t_pref = tokenizer(prefix, truncation=True, padding=False)\n",
        "    start_locs = len(t_pref[\"input_ids\"])\n",
        "\n",
        "    # 2) tokenizza la coppia vera e propria con pad/trunc\n",
        "    t_full = tokenizer(full, truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "    return {\n",
        "      \"input_ids\":      t_full[\"input_ids\"],\n",
        "      \"attention_mask\": t_full[\"attention_mask\"],\n",
        "      \"labels\":         t_full[\"input_ids\"],\n",
        "      \"start_locs\":     start_locs,\n",
        "    }\n",
        "\n",
        "\n",
        "ds_retain = Dataset.from_pandas(retain_train_df).map(\n",
        "    tokenize_with_start, batched=False, load_from_cache_file=False\n",
        ")\n",
        "\n",
        "ds_forget = Dataset.from_pandas(forget_train_df).map(\n",
        "    tokenize_with_start, batched=False, load_from_cache_file=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "aw0-fjfWEw5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "ds_retain_val = Dataset.from_pandas(retain_validation_df).map(\n",
        "    tokenize_with_start,\n",
        "    batched=False,\n",
        "    load_from_cache_file=False\n",
        ")\n",
        "ds_forget_val = Dataset.from_pandas(forget_validation_df).map(\n",
        "    tokenize_with_start,\n",
        "    batched=False,\n",
        "    load_from_cache_file=False\n",
        ")\n",
        "\n",
        "forget_val_loader = DataLoader(ds_forget_val, batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "retain_val_loader = DataLoader(ds_retain_val, batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "\n",
        "nll_forget_pre, ppl_forget_pre = eval_loss(pretrained_model, forget_val_loader)\n",
        "nll_retain_pre, ppl_retain_pre = eval_loss(pretrained_model, retain_val_loader)\n",
        "\n",
        "nll_forget_post, ppl_forget_post = eval_loss(unlearned_model, forget_val_loader)\n",
        "nll_retain_post, ppl_retain_post = eval_loss(unlearned_model, retain_val_loader)\n",
        "\n"
      ],
      "metadata": {
        "id": "dTZJyz_jse4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"nll_forget_pre: {nll_forget_pre:.2f}\")\n",
        "print(f\"ppl_forget_pre: {ppl_forget_pre:.2f}\")\n",
        "print(f\"nll_forget_post: {nll_forget_post:.2f}\")\n",
        "print(f\"ppl_forget_post: {ppl_forget_post:.2f}\")\n",
        "\n",
        "print(f\"nll_retain_pre: {nll_retain_pre:.2f}\")\n",
        "print(f\"ppl_retain_pre: {ppl_retain_pre:.2f}\")\n",
        "print(f\"nll_retain_post: {nll_retain_post:.2f}\")\n",
        "print(f\"ppl_retain_post: {ppl_retain_post:.2f}\")"
      ],
      "metadata": {
        "id": "iMCNBrf8uLyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, example in forget_validation_df.sample(5).iterrows():\n",
        "    prompt = example[\"input\"]\n",
        "    print(\"PROMPT:\", prompt)\n",
        "    out_pre  = pretrained_model.generate(tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device), max_new_tokens=50)\n",
        "    out_post = unlearned_model.generate(tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device), max_new_tokens=50)\n",
        "    print(\"ORIG:\", tokenizer.decode(out_pre[0], skip_special_tokens=True))\n",
        "    print(\"NEW:\",  tokenizer.decode(out_post[0], skip_special_tokens=True))\n",
        "    print(\"-\"*40)"
      ],
      "metadata": {
        "id": "JIQOsOG7skv5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}